{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataframe as Table ( may be useful when uploading to ```Mindomo``` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 創建一個 DataFrame\n",
    "df = pd.DataFrame({'name': ['Alice', 'Bob', 'Charlie', 'Dave'],\n",
    "                   'age': [25, 30, 35, 40],\n",
    "                   'gender': ['F', 'M', 'M', 'M']})\n",
    "\n",
    "# 將 DataFrame 轉換為圖片\n",
    "fig, ax =plt.subplots(figsize=(8,3))\n",
    "ax.axis('off')\n",
    "ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', bbox=[0, 0, 1, 1])\n",
    "plt.show()\n",
    "\n",
    "# buffer = BytesIO()\n",
    "# buffer.seek(0)\n",
    "# img = Image.open(buffer)\n",
    "\n",
    "# # 顯示圖片\n",
    "# img.show()\n",
    "\n",
    "# # 儲存圖片\n",
    "# img.save('my_table.png')\n",
    "\n",
    "fig.savefig('my_table.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import traceback\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\confocal_microscope\\Desktop\\ZebraFish_AP_POS\\modules\") # add path to scan customized module\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend, \\\n",
    "                     compose_transform, calculate_class_weight, get_sorted_classMap_from_dir\n",
    "from misc_utils import Timer\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_logger = init_logger(r\"Training\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_dataset_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\"\n",
    "save_dir_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test}_Model_history\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-03-25 14:34:46,442 | Training | INFO | Using 'cuda', device_name = 'NVIDIA GeForce RTX 2080 Ti'\n"
     ]
    }
   ],
   "source": [
    "dataset_name = r\"{20230305_NEW_STRUCT}_Academia_Sinica_i409\"\n",
    "dataset_gen_method = \"fish_dataset_horiz_cut_1l2_Mix_AP\"\n",
    "dataset_param_name = \"DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\"\n",
    "cuda_idx = 1\n",
    "label_in_filename = 0\n",
    "train_ratio = 0.8\n",
    "rand_seed = 2022\n",
    "model_name = \"vit_b_16\"\n",
    "pretrain_weights = \"IMAGENET1K_V1\"\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "lr = 1e-5\n",
    "use_hsv = False # using 'HSV' when getting images from the 'ImgDataset'\n",
    "aug_on_fly = True # applying augmentation on the fly\n",
    "forcing_balance = False\n",
    "forcing_sample_amount = 2800\n",
    "\n",
    "if aug_on_fly and forcing_balance: raise ValueError(\"'aug_on_fly' and 'forcing_balance' can only be set to True one at a time\")\n",
    "\n",
    "debug_mode = False # if True, sample 200 images only\n",
    "\n",
    "# Create path var\n",
    "save_dir_model = os.path.join(save_dir_root, model_name)\n",
    "train_selected_dir = os.path.join(ap_dataset_root, dataset_name, dataset_gen_method, dataset_param_name, \"train\", \"selected\")\n",
    "\n",
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "cli_logger.info(f\"Using '{device}', device_name = '{device_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-03-25 14:34:46,558 | Training | INFO | {'L': 0, 'M': 1, 'S': 2}\n",
      "| 2023-03-25 14:34:46,597 | Training | INFO | total = 1990\n",
      "| 2023-03-25 14:34:46,599 | Training | INFO | train_data (1592)\n",
      "| 2023-03-25 14:34:46,599 | Training | INFO | 0 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_120_P_selected_4.tiff\n",
      "| 2023-03-25 14:34:46,599 | Training | INFO | 1 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\M\\M_fish_94_P_selected_0.tiff\n",
      "| 2023-03-25 14:34:46,600 | Training | INFO | 2 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_19_P_selected_3.tiff\n",
      "| 2023-03-25 14:34:46,600 | Training | INFO | 3 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\L\\L_fish_200_P_selected_1.tiff\n",
      "| 2023-03-25 14:34:46,601 | Training | INFO | 4 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\M\\M_fish_153_A_selected_3.tiff\n",
      "| 2023-03-25 14:34:46,601 | Training | INFO | ※ : applying augmentation on the fly\n",
      "| 2023-03-25 14:34:46,602 | Training | INFO | ※ : total train batches: 50\n",
      "| 2023-03-25 14:34:46,602 | Training | INFO | valid_data (398)\n",
      "| 2023-03-25 14:34:46,603 | Training | INFO | 0 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\M\\M_fish_60_A_selected_3.tiff\n",
      "| 2023-03-25 14:34:46,603 | Training | INFO | 1 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\M\\M_fish_142_P_selected_1.tiff\n",
      "| 2023-03-25 14:34:46,603 | Training | INFO | 2 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_5_A_selected_3.tiff\n",
      "| 2023-03-25 14:34:46,603 | Training | INFO | 3 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_77_P_selected_4.tiff\n",
      "| 2023-03-25 14:34:46,604 | Training | INFO | 4 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_138_A_selected_0.tiff\n",
      "| 2023-03-25 14:34:46,604 | Training | INFO | ※ : total valid batches: 13\n",
      "| 2023-03-25 14:34:46,605 | Training | INFO | load model using 'torch.hub.load()', model_name: 'vit_b_16', pretrain_weights: 'IMAGENET1K_V1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: 'C:\\Users\\confocal_microscope\\Desktop\\{Test}_Model_history\\vit_b_16\\Training_20230325_14_34_46' is created!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\n",
      "C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ce367aad1b432980a30155556a9133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29ec1f2ea9a4cbb8fb3e3a9fcb292e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365e961050994b1fa590f90fbc245221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid :   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = 0.72456\n"
     ]
    }
   ],
   "source": [
    "# Create save model directory\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "save_dir = os.path.join(save_dir_model, f\"Training_{time_stamp}\")\n",
    "create_new_dir(save_dir)\n",
    "\n",
    "\n",
    "# Set 'np.random.seed'\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Create transform and Set 'rand_seed' if 'aug_on_fly' is True\n",
    "if aug_on_fly: \n",
    "    random.seed(rand_seed) # To get consistent augmentations ( 'albumentations' package )\n",
    "    transform = compose_transform()\n",
    "else: transform = None\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_map'\n",
    "class_map = get_sorted_classMap_from_dir(train_selected_dir)\n",
    "cli_logger.info(class_map)\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "dataset_img_dict = { \"all_classes\" : [] }\n",
    "# random sampling from each class with a constant value (forcing balance)\n",
    "if aug_on_fly: dataset_img_dict['all_classes'] = glob(os.path.normpath(f\"{train_selected_dir}/*/*selected*.tiff\"))\n",
    "elif forcing_balance:\n",
    "    for key, value in class_map.items(): # key: class, value: class_idx\n",
    "        dataset_img_dict[key] = glob(os.path.normpath(f\"{train_selected_dir}/{key}/*.tiff\"))\n",
    "        dataset_img_dict[key] = np.random.choice(dataset_img_dict[key], size=forcing_sample_amount, replace=False)\n",
    "        dataset_img_dict['all_classes'].extend(dataset_img_dict[key])\n",
    "else: dataset_img_dict['all_classes'] = glob(os.path.normpath(f\"{train_selected_dir}/*/*.tiff\"))\n",
    "cli_logger.info(f\"total = {len(dataset_img_dict['all_classes'])}\")\n",
    "## debug mode: random select 200 images\n",
    "if debug_mode:\n",
    "    dataset_img_dict['all_classes'] = np.random.choice(dataset_img_dict['all_classes'], size=200, replace=False)\n",
    "    cli_logger.info(f\"Debug mode, only select first {len(dataset_img_dict['all_classes'])}\")\n",
    "\n",
    "\n",
    "# Split train, test dataset\n",
    "train_img_list, valid_img_list = train_test_split(dataset_img_dict['all_classes'], random_state=rand_seed, train_size=train_ratio)\n",
    "## save 'training_amount'\n",
    "training_amount = f\"{{ dataset_{len(dataset_img_dict['all_classes'])} }}_{{ train_{len(train_img_list)} }}_{{ valid_{len(valid_img_list)} }}\"\n",
    "with open(os.path.normpath(f\"{save_dir}/{training_amount}\"), mode=\"w\") as f_writer: pass\n",
    "\n",
    "\n",
    "# Create 'train_set', 'train_dataloader'\n",
    "cli_logger.info(f\"train_data ({len(train_img_list)})\")\n",
    "[cli_logger.info(f\"{i} : img_path = {train_img_list[i]}\") for i in range(5)]\n",
    "train_set = ImgDataset(train_img_list, class_map=class_map, label_in_filename=label_in_filename, \n",
    "                       use_hsv=use_hsv, transform=transform, logger=cli_logger)\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True) # TODO:  Dataloader shuffle consistency\n",
    "cli_logger.info(f\"※ : total train batches: {len(train_dataloader)}\")\n",
    "\n",
    "\n",
    "# Create 'valid_set', 'valid_dataloader'\n",
    "cli_logger.info(f\"valid_data ({len(valid_img_list)})\")\n",
    "[cli_logger.info(f\"{i} : img_path = {valid_img_list[i]}\") for i in range(5)]\n",
    "valid_set = ImgDataset(valid_img_list, class_map=class_map, label_in_filename=label_in_filename, \n",
    "                       use_hsv=use_hsv)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "cli_logger.info(f\"※ : total valid batches: {len(valid_dataloader)}\")\n",
    "\n",
    "\n",
    "# Read test ( debug mode only )\n",
    "if debug_mode:\n",
    "    reat_test = cv2.imread(train_img_list[-1])\n",
    "    cli_logger.info(f\"Read Test: {train_img_list[-1]}\")\n",
    "    cv2.imshow(\"Read Test\", reat_test)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Create model\n",
    "cli_logger.info(f\"load model using 'torch.hub.load()', model_name: '{model_name}', pretrain_weights: '{pretrain_weights}'\")\n",
    "model = torch.hub.load('pytorch/vision', model_name, weights=pretrain_weights)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class_map), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "\n",
    "\n",
    "# Initial 'loss function' and 'optimizer'\n",
    "if aug_on_fly:\n",
    "    logs_path = os.path.join(ap_dataset_root, dataset_name, dataset_gen_method, \n",
    "                             dataset_param_name, r\"{Logs}_train_selected_summary.log\")\n",
    "    with open(logs_path, 'r') as f_writer: class_counts: Dict[str, int] = json.load(f_writer)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=calculate_class_weight(class_counts)) # apply 'class_weight'\n",
    "else: \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr) # TODO:  use momentum, lr_scheduler\n",
    "\n",
    "\n",
    "# Training\n",
    "## training variables\n",
    "training_timer = Timer()\n",
    "train_logs = []\n",
    "valid_logs = []\n",
    "## progress bar\n",
    "pbar_n_epoch = tqdm(total=epochs, desc=f\"Epoch \")\n",
    "pbar_n_train = tqdm(total=len(train_dataloader), desc=\"Train \")\n",
    "pbar_n_valid = tqdm(total=len(valid_dataloader), desc=\"Valid \")\n",
    "## best validation condition\n",
    "best_val_log = { \"Best\": time_stamp, \"epoch\": 0 }\n",
    "best_val_f1 = 0.0\n",
    "best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "best_optimizer_state_dict = copy.deepcopy(optimizer.state_dict())\n",
    "## start training\n",
    "## TODO:  interrupt during training\n",
    "## TODO:  recover training\n",
    "training_timer.start()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # One-based iteration\n",
    "    epoch_one_based = epoch+1\n",
    "    \n",
    "    # Update progress bar description\n",
    "    pbar_n_epoch.desc = f\"Epoch {epoch_one_based} \"\n",
    "    pbar_n_epoch.refresh()\n",
    "    pbar_n_train.n = 0\n",
    "    pbar_n_train.refresh()\n",
    "    pbar_n_valid.n = 0\n",
    "    pbar_n_valid.refresh()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Training\n",
    "    ## reset variables\n",
    "    epoch_train_log = { \"Train\": \"\", \"epoch\": epoch_one_based }\n",
    "    pred_list = []\n",
    "    gt_list = []\n",
    "    accum_batch_loss = 0.0\n",
    "    ## set to training mode\n",
    "    model.train()\n",
    "    for data in train_dataloader:\n",
    "        x_train, y_train = data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device) # move to GPU\n",
    "        preds = model(x_train)\n",
    "        loss_value = loss_fn(preds, y_train)\n",
    "        \n",
    "        ## update mode_parameters by back_propagation\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() # clean gradients after step\n",
    "        \n",
    "        ## extend 'pred_list', 'gt_list'\n",
    "        _, pred_train = torch.max(preds, 1) # get the highest probability class\n",
    "        pred_list.extend(pred_train.cpu().numpy().tolist()) # conversion flow: Tensor --> ndarray --> list\n",
    "        gt_list.extend(y_train.cpu().numpy().tolist())\n",
    "        ## add current batch loss\n",
    "        accum_batch_loss += loss_value.item() # get value of Tensor\n",
    "        \n",
    "        ## update 'pbar_n_train'\n",
    "        pbar_n_train.update(1)\n",
    "        pbar_n_train.refresh()\n",
    "    \n",
    "    caulculate_metrics(epoch_train_log, (accum_batch_loss/len(train_dataloader)),\n",
    "                       gt_list, pred_list, class_map)\n",
    "    # print(json.dumps(epoch_train_log, indent=4))\n",
    "    train_logs.append(epoch_train_log)\n",
    "    ## update postfix of 'pbar_n_train'\n",
    "    pbar_n_train.postfix = f\" {'{'} Loss: {epoch_train_log['average_loss']}, Avg_f1: {epoch_train_log['average_f1']} {'}'} \"\n",
    "    pbar_n_train.refresh()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Validating\n",
    "    ## reset variables\n",
    "    epoch_valid_log = { \"Valid\": \"\", \"epoch\": epoch_one_based }\n",
    "    pred_list = []\n",
    "    gt_list = []\n",
    "    accum_batch_loss = 0.0\n",
    "    ## set to evaluation mode\n",
    "    model.eval() \n",
    "    with torch.no_grad(): \n",
    "        for data in valid_dataloader:\n",
    "            x_valid, y_valid = data\n",
    "            x_valid, y_valid = x_valid.to(device), y_valid.to(device) # move to GPU\n",
    "            preds = model(x_valid)\n",
    "            loss_value = loss_fn(preds, y_valid)\n",
    "            \n",
    "            ## extend 'pred_list', 'gt_list'\n",
    "            _, pred_valid = torch.max(preds, 1)\n",
    "            pred_list.extend(pred_valid.cpu().numpy().tolist())\n",
    "            gt_list.extend(y_valid.cpu().numpy().tolist())\n",
    "            ## add current batch loss\n",
    "            accum_batch_loss += loss_value.item()\n",
    "            \n",
    "            ## update 'pbar_n_valid'\n",
    "            pbar_n_valid.update(1)\n",
    "            pbar_n_valid.refresh()\n",
    "\n",
    "    caulculate_metrics(epoch_valid_log, (accum_batch_loss/len(valid_dataloader)),\n",
    "                       gt_list, pred_list, class_map)\n",
    "    # print(json.dumps(epoch_valid_log, indent=4))\n",
    "    valid_logs.append(epoch_valid_log)\n",
    "    ## update postfix of 'pbar_n_valid'\n",
    "    pbar_n_valid.postfix = f\" {'{'} Loss: {epoch_valid_log['average_loss']}, Avg_f1: {epoch_valid_log['average_f1']} {'}'} \"\n",
    "    pbar_n_valid.refresh()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO:  Early stop\n",
    "    \n",
    "    \n",
    "    # Check best condition, average_f1 = (macro_f1 + micro_f1)/2\n",
    "    if epoch_valid_log[\"average_f1\"] > best_val_f1:\n",
    "        best_val_f1 = epoch_valid_log[\"average_f1\"]\n",
    "        tqdm.write(f\"Epoch: {epoch_one_based}, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = {epoch_valid_log['average_f1']}\")\n",
    "        ## update 'best_val_log'\n",
    "        best_val_log[\"epoch\"] = epoch_one_based\n",
    "        caulculate_metrics(best_val_log, (accum_batch_loss/len(valid_dataloader)),\n",
    "                           gt_list, pred_list, class_map)\n",
    "        best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "        best_optimizer_state_dict = copy.deepcopy(optimizer.state_dict())\n",
    "    \n",
    "    # Update figure \n",
    "    plot_training_trend_kwargs = {\n",
    "        \"plt\"        : plt,\n",
    "        \"save_dir\"   : save_dir,\n",
    "        \"loss_key\"   : \"average_loss\",\n",
    "        \"score_key\"  : \"average_f1\",\n",
    "        \"train_logs\" : pd.DataFrame(train_logs),\n",
    "        \"valid_logs\" : pd.DataFrame(valid_logs),\n",
    "    }\n",
    "    plot_training_trend(**plot_training_trend_kwargs)\n",
    "    \n",
    "    # Update 'pbar_n_epoch'\n",
    "    pbar_n_epoch.update(1)\n",
    "    pbar_n_epoch.refresh()\n",
    "\n",
    "\n",
    "pbar_n_epoch.close()\n",
    "pbar_n_train.close()\n",
    "pbar_n_valid.close()\n",
    "## end training\n",
    "\n",
    "\n",
    "# Save training consume time\n",
    "training_timer.stop()\n",
    "training_timer.calculate_consume_time()\n",
    "training_timer.save_consume_time(save_dir, desc=\"training time\")\n",
    "\n",
    "\n",
    "# Save model\n",
    "save_model(\"best\", save_dir, best_model_state_dict, best_optimizer_state_dict, best_val_log)\n",
    "save_model(\"final\", save_dir, model.state_dict(), optimizer.state_dict(), {\"train\": train_logs, \"valid\": valid_logs})\n",
    "\n",
    "\n",
    "# Save log (convert to Dataframe)\n",
    "df_train_logs = pd.DataFrame(train_logs)\n",
    "df_train_logs.set_index(\"epoch\", inplace=True)\n",
    "df_train_logs.to_excel(os.path.join(save_dir, \"{Logs}_train.xlsx\"), engine=\"openpyxl\")\n",
    "df_valid_logs = pd.DataFrame(valid_logs)\n",
    "df_valid_logs.set_index(\"epoch\", inplace=True)\n",
    "df_valid_logs.to_excel(os.path.join(save_dir, \"{Logs}_valid.xlsx\"), engine=\"openpyxl\")\n",
    "with open(os.path.normpath(f\"{save_dir}/{{Logs}}_best_valid.log\"), mode=\"w\") as f_writer:\n",
    "    f_writer.write(json.dumps(best_val_log, indent=4))\n",
    "\n",
    "\n",
    "# Rename 'save_dir'\n",
    "## new_name_format = {time_stamp}_{status}_{target_epoch_with_ImgLoadOptions}_{test_f1}\n",
    "## status = {EarlyStop, Interrupt, Completed, Tested, etc.}\n",
    "new_name_desc3 = f\"{epochs}_epochs\"\n",
    "if aug_on_fly: new_name_desc3 += \"_AugOnFly\"\n",
    "if use_hsv: new_name_desc3 += \"_HSV\"\n",
    "new_name = f\"{time_stamp}_{{Completed}}_{{{new_name_desc3}}}\"\n",
    "os.rename(save_dir, os.path.join(save_dir_model, new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
