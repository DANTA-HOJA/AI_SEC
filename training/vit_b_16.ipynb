{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import traceback\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\confocal_microscope\\Desktop\\ZebraFish_AP_POS\\modules\") # add path to scan customized module\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = init_logger(r\"Training\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_dataset_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\"\n",
    "save_dir_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test}_Model_history\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-03-21 12:49:04,717 | Training | INFO | Using 'cuda', device_name = 'NVIDIA GeForce RTX 2080 Ti'\n"
     ]
    }
   ],
   "source": [
    "dataset_name = r\"{20230305_NEW_STRUCT}_Academia_Sinica_i409\"\n",
    "dataset_gen_method = \"fish_dataset_horiz_cut_1l2_Mix_AP\"\n",
    "dataset_param_name = \"DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\"\n",
    "cuda_idx = 1\n",
    "label_in_filename = 0\n",
    "train_ratio = 0.8\n",
    "rand_seed = 2022\n",
    "model_name = \"vit_b_16\"\n",
    "pretrain_weights = \"IMAGENET1K_V1\"\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "lr = 1e-5\n",
    "\n",
    "debug_mode = False\n",
    "\n",
    "# Create path var\n",
    "save_dir_model = os.path.join(save_dir_root, model_name)\n",
    "train_selected_dir = os.path.join(ap_dataset_root, dataset_name, dataset_gen_method, dataset_param_name, \"train\", \"selected\")\n",
    "\n",
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "log.info(f\"Using '{device}', device_name = '{device_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-03-21 12:49:04,847 | Training | INFO | {'L': 0, 'M': 1, 'S': 2}\n",
      "| 2023-03-21 12:49:04,900 | Training | INFO | total = 9310\n",
      "| 2023-03-21 12:49:04,902 | Training | INFO | train_data (7448)\n",
      "| 2023-03-21 12:49:04,903 | Training | INFO | 0：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_43_A_selected_3.tiff\n",
      "| 2023-03-21 12:49:04,904 | Training | INFO | 1：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\M\\M_fish_55_P_selected_1.tiff\n",
      "| 2023-03-21 12:49:04,904 | Training | INFO | 2：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\M\\M_fish_29_P_aug_Wx8w1pgM.tiff\n",
      "| 2023-03-21 12:49:04,904 | Training | INFO | 3：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_28_A_aug_opmHedJY.tiff\n",
      "| 2023-03-21 12:49:04,905 | Training | INFO | 4：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_50_P_aug_sGOXffpS.tiff\n",
      "| 2023-03-21 12:49:04,905 | Training | INFO | test_data (1862)\n",
      "| 2023-03-21 12:49:04,906 | Training | INFO | 0：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\L\\L_fish_184_A_selected_3.tiff\n",
      "| 2023-03-21 12:49:04,906 | Training | INFO | 1：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\S\\S_fish_14_A_aug_j5vGCvV4.tiff\n",
      "| 2023-03-21 12:49:04,906 | Training | INFO | 2：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\L\\L_fish_173_P_aug_ihvvUnXX.tiff\n",
      "| 2023-03-21 12:49:04,907 | Training | INFO | 3：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\M\\M_fish_108_P_aug_0BlMA6p1.tiff\n",
      "| 2023-03-21 12:49:04,907 | Training | INFO | 4：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\train\\selected\\L\\L_fish_192_A_selected_3.tiff\n",
      "| 2023-03-21 12:49:04,909 | Training | INFO | total train batches: 233\n",
      "| 2023-03-21 12:49:04,910 | Training | INFO | total valid batches: 59\n",
      "| 2023-03-21 12:49:04,910 | Training | INFO | load model using 'torch.hub.load()', model_name:'vit_b_16', pretrain_weights:'IMAGENET1K_V1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: 'C:\\Users\\confocal_microscope\\Desktop\\{Test}_Model_history\\vit_b_16\\Training_20230321_12_49_04' is created!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\n",
      "C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54925605323f4a54816479ea683417a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d200fad73848413ea2cc66e1613c1de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab83340090440a59f341da87a767e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid :   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = 0.8698343316693342\n",
      "Epoch: 2, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = 0.9332807626640378\n",
      "Epoch: 5, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = 0.943402316341849\n",
      "Epoch: 7, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = 0.9579579618928912\n",
      "Epoch: 8, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = 0.9628314656992757\n"
     ]
    }
   ],
   "source": [
    "# Create save model directory\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "save_dir = os.path.join(save_dir_model, f\"Training_{time_stamp}\")\n",
    "create_new_dir(save_dir)\n",
    "\n",
    "\n",
    "## set random seed\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_map'\n",
    "all_class_list = glob(os.path.normpath(f\"{train_selected_dir}/*\"))\n",
    "all_class_list = [path.split(os.sep)[-1] for path in all_class_list]\n",
    "all_class_list.sort()\n",
    "class_map = {cls:i for i, cls in enumerate(all_class_list)}\n",
    "log.info(class_map)\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "dataset_img_list = glob(os.path.normpath(f\"{train_selected_dir}/*/*.tiff\"))\n",
    "log.info(f\"total = {len(dataset_img_list)}\")\n",
    "## debug mode: only select first 200\n",
    "if debug_mode:\n",
    "    dataset_img_list = np.random.choice(dataset_img_list, size=200, replace=False)\n",
    "    log.info(f\"Debug mode, only select first {len(dataset_img_list)}\")\n",
    "\n",
    "\n",
    "# Split train, test dataset\n",
    "train_img_list, valid_img_list = train_test_split(dataset_img_list, random_state=rand_seed, train_size=train_ratio)\n",
    "## train\n",
    "log.info(f\"train_data ({len(train_img_list)})\")\n",
    "[log.info(f\"{i}：img_path = {train_img_list[i]}\") for i in range(5)]\n",
    "## test\n",
    "log.info(f\"test_data ({len(valid_img_list)})\")\n",
    "[log.info(f\"{i}：img_path = {valid_img_list[i]}\") for i in range(5)]\n",
    "## debug mode: read test\n",
    "if debug_mode:\n",
    "    reat_test = cv2.imread(train_img_list[-1])\n",
    "    log.info(f\"Read Test: {train_img_list[-1]}\")\n",
    "    cv2.imshow(\"Read Test\", reat_test)\n",
    "    cv2.waitKey(0)\n",
    "## save 'training_amount'\n",
    "training_amount = f\"{{ dataset_{len(dataset_img_list)} }}_{{ train_{len(train_img_list)} }}_{{ valid_{len(valid_img_list)} }}\"\n",
    "f_writer = open(os.path.normpath(f\"{save_dir}/{training_amount}\"), mode=\"w\")\n",
    "f_writer.close()\n",
    "\n",
    "\n",
    "# Create dataSets\n",
    "train_set = ImgDataset(train_img_list, class_map=class_map, label_in_filename=label_in_filename)\n",
    "valid_set = ImgDataset(valid_img_list, class_map=class_map, label_in_filename=label_in_filename)\n",
    "\n",
    "\n",
    "# Initial dataLoader\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True) # TODO:  Dataloader shuffle consistency\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "log.info(f\"total train batches: {len(train_dataloader)}\")\n",
    "log.info(f\"total valid batches: {len(valid_dataloader)}\")\n",
    "\n",
    "\n",
    "# Create model\n",
    "log.info(f\"load model using 'torch.hub.load()', model_name:'{model_name}', pretrain_weights:'{pretrain_weights}'\")\n",
    "model = torch.hub.load('pytorch/vision', model_name, weights=pretrain_weights)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class_map), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "\n",
    "\n",
    "# Initial loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # TODO:  add 'class_weight'\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr) # TODO:  use momentum, lr_scheduler\n",
    "\n",
    "\n",
    "# Training\n",
    "## training variables\n",
    "train_logs = []\n",
    "valid_logs = []\n",
    "## progress bar\n",
    "pbar_n_epoch = tqdm(total=epochs, desc=f\"Epoch \")\n",
    "pbar_n_train = tqdm(total=len(train_dataloader), desc=\"Train \")\n",
    "pbar_n_valid = tqdm(total=len(valid_dataloader),desc=\"Valid \")\n",
    "## best condition\n",
    "best_log = {\n",
    "    'epoch' : 0,\n",
    "    'best_val_avg_loss': np.inf,\n",
    "    'best_val_avg_f1': 0.0, # average_f1 = (macro_f1 + micro_f1) / 2\n",
    "}\n",
    "best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "best_optimizer_state_dict = copy.deepcopy(optimizer.state_dict())\n",
    "## start training\n",
    "### TODO:  interrupt during training\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # One-based iteration\n",
    "    epoch_one_based = epoch+1\n",
    "    \n",
    "    # Update progress bar description\n",
    "    pbar_n_epoch.desc = f\"Epoch {epoch_one_based} \"\n",
    "    pbar_n_epoch.refresh()\n",
    "    pbar_n_train.n = 0\n",
    "    pbar_n_train.refresh()\n",
    "    pbar_n_valid.n = 0\n",
    "    pbar_n_valid.refresh()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Training\n",
    "    ## reset variables\n",
    "    epoch_train_log = { \"Train\": \"\", \"epoch\": epoch_one_based }\n",
    "    pred_list = []\n",
    "    gt_list = []\n",
    "    accum_batch_loss = 0.0\n",
    "    ## set to training mode\n",
    "    model.train()\n",
    "    for data in train_dataloader:\n",
    "        x_train, y_train = data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device) # move to GPU\n",
    "        preds = model(x_train)\n",
    "        loss_value = loss_fn(preds, y_train)\n",
    "        _, pred_train = torch.max(preds, 1) # get the highest probability\n",
    "        \n",
    "        ## update mode_parameters by back_propagation\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() # clean gradients after step\n",
    "        \n",
    "        ## extend 'pred_list', 'gt_list'\n",
    "        pred_list.extend(pred_train.cpu().numpy().tolist())\n",
    "        gt_list.extend(y_train.cpu().numpy().tolist())\n",
    "        ## add current batch loss\n",
    "        accum_batch_loss += loss_value.item()\n",
    "        \n",
    "        ## update 'pbar_n_train'\n",
    "        pbar_n_train.update(1)\n",
    "        pbar_n_train.refresh()\n",
    "    \n",
    "    caulculate_metrics(epoch_train_log, accum_batch_loss, len(train_dataloader),\n",
    "                       gt_list, pred_list, class_map)\n",
    "    # print(json.dumps(epoch_train_log, indent=4))\n",
    "    train_logs.append(epoch_train_log)\n",
    "    ## update postfix of 'pbar_n_train'\n",
    "    pbar_n_train.postfix = \" {} Loss:{:.4f}, Avg_f1: {:.4f} {} \".format(\"{\", epoch_train_log[\"avg_loss\"],\n",
    "                                                                        epoch_train_log[\"average_f1\"], \"}\")\n",
    "    pbar_n_train.refresh()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Validating\n",
    "    ## reset variables\n",
    "    epoch_valid_log = { \"Valid\": \"\", \"epoch\": epoch_one_based }\n",
    "    pred_list = []\n",
    "    gt_list = []\n",
    "    accum_batch_loss = 0.0\n",
    "    ## set to evaluation mode\n",
    "    model.eval() \n",
    "    with torch.no_grad(): \n",
    "        for data in valid_dataloader:\n",
    "            x_valid, y_valid = data\n",
    "            x_valid, y_valid = x_valid.to(device), y_valid.to(device) # move to GPU\n",
    "            preds = model(x_valid)\n",
    "            loss_value = loss_fn(preds, y_valid)\n",
    "            _, pred_valid = torch.max(preds, 1)\n",
    "            \n",
    "            ## extend 'pred_list', 'gt_list'\n",
    "            pred_list.extend(pred_valid.cpu().numpy().tolist())\n",
    "            gt_list.extend(y_valid.cpu().numpy().tolist())\n",
    "            ## add current batch loss\n",
    "            accum_batch_loss += loss_value.item()\n",
    "            \n",
    "            ## update 'pbar_n_valid'\n",
    "            pbar_n_valid.update(1)\n",
    "            pbar_n_valid.refresh()\n",
    "\n",
    "    caulculate_metrics(epoch_valid_log, accum_batch_loss, len(valid_dataloader),\n",
    "                       gt_list, pred_list, class_map)\n",
    "    # print(json.dumps(epoch_valid_log, indent=4))\n",
    "    valid_logs.append(epoch_valid_log)\n",
    "    ## update postfix of 'pbar_n_valid'\n",
    "    pbar_n_valid.postfix = \" {} Loss:{:.4f}, Avg_f1: {:.4f} {} \".format(\"{\", epoch_valid_log[\"avg_loss\"],\n",
    "                                                                        epoch_valid_log[\"average_f1\"], \"}\")\n",
    "    pbar_n_valid.refresh()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO:  Early stop\n",
    "    \n",
    "    \n",
    "    # Check best condition, average_f1 = (macro_f1 + micro_f1)/2\n",
    "    if epoch_valid_log[\"average_f1\"] > best_log[\"best_val_avg_f1\"]:\n",
    "        best_log[\"epoch\"] = epoch_one_based\n",
    "        best_log[\"best_val_avg_loss\"] = epoch_valid_log[\"avg_loss\"]\n",
    "        best_log[\"best_val_avg_f1\"] = epoch_valid_log[\"average_f1\"]\n",
    "        tqdm.write(\"Epoch: {}, ☆★☆ BEST_VALIDATION ☆★☆, best_val_avg_f1 = {}\".format(epoch_one_based, epoch_valid_log[\"average_f1\"]))\n",
    "        best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "        best_optimizer_state_dict = copy.deepcopy(optimizer.state_dict())\n",
    "    \n",
    "    # Update figure \n",
    "    plot_training_trend_kwargs = {\n",
    "        \"plt\"        : plt,\n",
    "        \"save_dir\"   : save_dir,\n",
    "        \"loss_key\"   : \"avg_loss\",\n",
    "        \"score_key\"  : \"average_f1\",\n",
    "        \"train_logs\" : pd.DataFrame(train_logs),\n",
    "        \"valid_logs\" : pd.DataFrame(valid_logs),\n",
    "    }\n",
    "    plot_training_trend(**plot_training_trend_kwargs)\n",
    "    \n",
    "    # Update 'pbar_n_epoch'\n",
    "    pbar_n_epoch.update(1)\n",
    "    pbar_n_epoch.refresh()\n",
    "\n",
    "\n",
    "pbar_n_epoch.close()\n",
    "pbar_n_train.close()\n",
    "pbar_n_valid.close()\n",
    "## end training\n",
    "\n",
    "\n",
    "# Save 'consume_time'\n",
    "stop_time = time.time() \n",
    "consume_time = stop_time - start_time\n",
    "consume_time_str = f\"{{consume_time}}_{{ {consume_time:.4f} sec }}\"\n",
    "f_writer = open(os.path.normpath(f\"{save_dir}/{consume_time_str}\"), mode=\"w\")\n",
    "f_writer.write(f\"{consume_time}\")\n",
    "f_writer.close()\n",
    "\n",
    "\n",
    "# Save model\n",
    "save_model(\"best\", save_dir, best_model_state_dict, best_optimizer_state_dict, best_log)\n",
    "save_model(\"final\", save_dir, model.state_dict(), optimizer.state_dict(), {\"train\": train_logs, \"valid\": valid_logs})\n",
    "\n",
    "\n",
    "# Save log (convert to Dataframe)\n",
    "df_train_logs = pd.DataFrame(train_logs)\n",
    "df_train_logs.set_index(\"epoch\", inplace=True)\n",
    "df_valid_logs = pd.DataFrame(valid_logs)\n",
    "df_valid_logs.set_index(\"epoch\", inplace=True)\n",
    "df_train_logs.to_excel(os.path.join(save_dir, \"{Logs}_train.xlsx\"), engine=\"openpyxl\")\n",
    "df_valid_logs.to_excel(os.path.join(save_dir, \"{Logs}_valid.xlsx\"), engine=\"openpyxl\")\n",
    "f_writer = open(os.path.normpath(f\"{save_dir}/{{Logs}}_best.log\"), mode=\"w\")\n",
    "f_writer.write(json.dumps(best_log, indent=4))\n",
    "f_writer.close()\n",
    "\n",
    "\n",
    "# Rename 'save_dir', \n",
    "# new_name_format = {time_stamp}_{status}_{target_epoch}_{test_f1}\n",
    "# status = {early_stop, interrupt, Completed, Tested, etc.}\n",
    "new_name = f\"{time_stamp}_{{Completed}}_{{{epochs}_epochs}}\"\n",
    "os.rename(save_dir, os.path.join(save_dir_model, new_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Dataframe as Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 創建一個 DataFrame\n",
    "df = pd.DataFrame({'name': ['Alice', 'Bob', 'Charlie', 'Dave'],\n",
    "                   'age': [25, 30, 35, 40],\n",
    "                   'gender': ['F', 'M', 'M', 'M']})\n",
    "\n",
    "# 將 DataFrame 轉換為圖片\n",
    "fig, ax =plt.subplots(figsize=(8,3))\n",
    "ax.axis('off')\n",
    "ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', bbox=[0, 0, 1, 1])\n",
    "plt.show()\n",
    "# buffer = BytesIO()\n",
    "fig.savefig('my_table.png')\n",
    "# buffer.seek(0)\n",
    "# img = Image.open(buffer)\n",
    "\n",
    "# # 顯示圖片\n",
    "# img.show()\n",
    "\n",
    "# # 儲存圖片\n",
    "# img.save('my_table.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
