{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for `Testing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "import json\n",
    "import toml\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "rel_module_path = \"./../../modules/\"\n",
    "sys.path.append( str(Path(rel_module_path).resolve()) ) # add path to scan customized module\n",
    "\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend, \\\n",
    "                     confusion_matrix_with_class, get_sortedClassMapper_from_dir\n",
    "from plt_show import plot_in_rgb # server can't use `cv.imshow()`\n",
    "\n",
    "config_dir = Path( \"./../../Config/\" ).resolve()\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredByImg_logger = init_logger(r\"Predict By Image\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `db_path_plan.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_dir.joinpath(\"db_path_plan.toml\"), mode=\"r\") as f_reader:\n",
    "    dbpp_config = toml.load(f_reader)\n",
    "\n",
    "db_root = Path(dbpp_config[\"root\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `(PredByImg)_vit_b_16.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_dir.joinpath(\"(PredByImg)_vit_b_16.toml\"), mode=\"r\") as f_reader:\n",
    "    config = toml.load(f_reader)\n",
    "    \n",
    "batch_size        = config[\"test_opts\"][\"batch_size\"]\n",
    "debug_mode        = config[\"test_opts\"][\"debug_mode\"][\"enable\"]\n",
    "debug_rand_select = config[\"test_opts\"][\"debug_mode\"][\"rand_select\"]\n",
    "cuda_idx          = config[\"test_opts\"][\"cuda\"][\"index\"]\n",
    "\n",
    "model_history = config[\"model_prediction\"][\"history\"]\n",
    "model_desc    = config[\"model_prediction\"][\"desc\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `train_config.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir_root = db_root.joinpath(dbpp_config[\"model_prediction\"])\n",
    "load_dir = os.path.join(load_dir_root, model_history)\n",
    "train_config_path = os.path.join(load_dir, r\"train_config.toml\")\n",
    "\n",
    "with open(train_config_path, mode=\"r\") as f_reader:\n",
    "    train_config = toml.load(f_reader)\n",
    "\n",
    "dataset_name             = train_config[\"dataset\"][\"name\"]\n",
    "dataset_result_alias     = train_config[\"dataset\"][\"result_alias\"]\n",
    "dataset_gen_method       = train_config[\"dataset\"][\"gen_method\"]\n",
    "dataset_classif_strategy = train_config[\"dataset\"][\"classif_strategy\"]\n",
    "dataset_param_name       = train_config[\"dataset\"][\"param_name\"]\n",
    "\n",
    "model_name = train_config[\"model\"][\"model_name\"]\n",
    "\n",
    "rand_seed = train_config[\"train_opts\"][\"random_seed\"]\n",
    "use_hsv   = train_config[\"train_opts\"][\"data\"][\"use_hsv\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate `path_vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cropped_root = db_root.joinpath(dbpp_config[\"dataset_cropped\"])\n",
    "dataset_dir = dataset_cropped_root.joinpath(dataset_name, dataset_result_alias, dataset_gen_method, \n",
    "                                                      dataset_classif_strategy, dataset_param_name)\n",
    "assert dataset_dir.exists(), f\"Can't find directory: '{dataset_dir}'\"\n",
    "\n",
    "test_selected_dir = os.path.join(dataset_dir, \"test\", \"selected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "PredByImg_logger.info(f\"Using '{device}', device_name = '{device_name}'\")\n",
    "\n",
    "\n",
    "# Get datetime\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "\n",
    "# Set 'np.random.seed'\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_mapper'\n",
    "num2class_list, class2num_dict = get_sortedClassMapper_from_dir(test_selected_dir)\n",
    "PredByImg_logger.info(f\"num2class_list = {num2class_list}, class2num_dict = {class2num_dict}\")\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "test_img_list = glob(os.path.normpath(f\"{test_selected_dir}/*/*.tiff\"))\n",
    "PredByImg_logger.info(f\"total = {len(test_img_list)}\")\n",
    "## debug mode: random select [debug_rand_select] images\n",
    "if debug_mode:\n",
    "    test_img_list = np.random.choice(test_img_list, size=debug_rand_select, replace=False)\n",
    "    PredByImg_logger.info(f\"Debug mode, only select first {len(test_img_list)}\")\n",
    "\n",
    "\n",
    "# Save 'testing_amount'\n",
    "testing_amount = f\"{{ datatest_{len(test_img_list)} }}_{{ test_{len(test_img_list)} }}\"\n",
    "with open(os.path.normpath(f\"{load_dir}/{testing_amount}\"), mode=\"w\") as f_writer: pass\n",
    "\n",
    "\n",
    "# Create 'test_set', 'test_dataloader'\n",
    "PredByImg_logger.info(f\"test_data ({len(test_img_list)})\")\n",
    "[PredByImg_logger.info(f\"{i} : img_path = {test_img_list[i]}\") for i in range(5)]\n",
    "test_set = ImgDataset(test_img_list, class_mapper=class2num_dict, resize=(224, 224), \n",
    "                      use_hsv=use_hsv)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "PredByImg_logger.info(f\"â€» : total test batches: {len(test_dataloader)}\")\n",
    "\n",
    "\n",
    "# Read test ( debug mode only )\n",
    "if debug_mode:\n",
    "    PredByImg_logger.info(f\"Read Test: {test_img_list[-1]}\")\n",
    "    plot_in_rgb(test_img_list[-1], (512, 512))\n",
    "\n",
    "\n",
    "# Create model ( ref: https://github.com/pytorch/vision/issues/7397 )\n",
    "PredByImg_logger.info((f\"load model from `torchvision`, \"\n",
    "                          f\"model_name: '{model_name}', weights: '{model_name}/{model_history}/{model_desc}_model.pth'\"))\n",
    "model = getattr(torchvision.models, model_name)\n",
    "model = model(weights=None)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class2num_dict), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "## load 'model_state_dict'\n",
    "model_path = os.path.join(load_dir, f\"{model_desc}_model.pth\")\n",
    "pth_file = torch.load(model_path, map_location=device) # unpack to device directly\n",
    "model.load_state_dict(pth_file[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "# Testing\n",
    "## testing variable\n",
    "test_f1_log = {}\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "## progress bar\n",
    "pbar_n_test = tqdm(total=len(test_dataloader), desc=\"Test \")\n",
    "## start testing\n",
    "## set to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        x_test, y_test, crop_name_batch = data\n",
    "        x_test, y_test = x_test.to(device), y_test.to(device) # move to GPU\n",
    "        preds = model(x_test)\n",
    "        pred_prob = torch.nn.functional.softmax(preds, dim=1)\n",
    "        _, pred_test = torch.max(pred_prob, 1)\n",
    "        \n",
    "        ## extend 'pred_list', 'gt_list'\n",
    "        pred_list.extend(pred_test.cpu().numpy().tolist())\n",
    "        gt_list.extend(y_test.cpu().numpy().tolist())\n",
    "        \n",
    "        ## show predict_status of current_batch in CLI\n",
    "        PredByImg_logger.info((f\"Batch[ {(batch+1):0{len(str(len(test_dataloader)))}} / {len(test_dataloader)} ], \"\n",
    "                               f\"# of (ground truth == prediction) in this batch : \"\n",
    "                               f\"{(pred_test.cpu() == y_test.cpu()).sum().item():{len(str(len(y_test)))}}/{len(y_test)}\"))\n",
    "        \n",
    "        ## update 'pbar_n_test'\n",
    "        pbar_n_test.update(1)\n",
    "        pbar_n_test.refresh()\n",
    "\n",
    "pbar_n_test.close()\n",
    "## end testing\n",
    "\n",
    "\n",
    "gt_list_to_name = [ num2class_list[i] for i in gt_list ]\n",
    "pred_list_to_name = [ num2class_list[i] for i in pred_list ]\n",
    "\n",
    "caulculate_metrics(test_f1_log, None,\n",
    "                   gt_list_to_name, pred_list_to_name, class2num_dict)\n",
    "# print(json.dumps(test_f1_log, indent=4))\n",
    "\n",
    "\n",
    "# Save `test_f1_log`\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Logs}}_PredByImg_maweavg_f1_{test_f1_log['maweavg_f1']}.toml\"), mode=\"w\") as f_writer:\n",
    "    f_writer.write(toml.dumps(test_f1_log))\n",
    "\n",
    "# Save infomations to a file\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Report}}_PredByImg.log\"), mode=\"w\") as f_writer:\n",
    "\n",
    "    ## change direction of 'sys.stdout'\n",
    "    orig_stdout = sys.stdout # store original 'sys.stdout'\n",
    "    sys.stdout = f_writer\n",
    "\n",
    "    ## write `config`\n",
    "    config_in_report = deepcopy(config[\"model_prediction\"])\n",
    "    print(\"[ model_prediction ]\"); print(toml.dumps(config_in_report))\n",
    "    \n",
    "    config_in_report = deepcopy(train_config[\"dataset\"])\n",
    "    print(\"[ dataset ]\"); print(toml.dumps(config_in_report))\n",
    "    \n",
    "    print(f\"â€» For more detail info please refer to its 'train_config' file...\\n\\n\") # newline\n",
    "\n",
    "\n",
    "    ## write 'classification_report'\n",
    "    cls_report = classification_report(y_true=gt_list_to_name, y_pred=pred_list_to_name, digits=5)\n",
    "    print(\"Classification Report:\\n\"); print(f\"{cls_report}\\n\")\n",
    "\n",
    "    ## write 'confusion_matrix'\n",
    "    #   row: Ground truth\n",
    "    #   column: predict\n",
    "    #  *ã€€0ã€€1ã€€2\n",
    "    #  0 [] [] []\n",
    "    #  1 [] [] []\n",
    "    #  2 [] [] []\n",
    "    #\n",
    "    confusion_mat = confusion_matrix_with_class(ground_truth=gt_list_to_name, prediction=pred_list_to_name)\n",
    "\n",
    "    ## recover direct of 'sys.stdout'\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "\n",
    "# Rename 'load_dir'\n",
    "## new_name_format = {time_stamp}_{state}_{target_epochs_with_ImgLoadOptions}_{test_f1}\n",
    "## state = {EarlyStop, Interrupt, Completed, Tested, etc.}\n",
    "model_history_list = re.split(\"{|}\", model_history)\n",
    "new_name = f\"{model_history_list[0]}{{Tested_PredByImg}}_{{{model_history_list[3]}}}_{{{model_desc}}}_{{maweavg_f1_{test_f1_log['maweavg_f1']}}}\" \n",
    "os.rename(load_dir, os.path.join(load_dir_root, new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae46fe3be2f97d3a16702042bc6c7abd422dd0bfb5ce5527ad30c3a287e1c756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
