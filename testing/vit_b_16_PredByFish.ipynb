{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for ```Testing``` ( Most common class for all sub-images of one fish )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import traceback\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\confocal_microscope\\Desktop\\ZebraFish_AP_POS\\modules\") # add path to scan customized module\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend, \\\n",
    "                     confusion_matrix_with_class, get_sortedClassMapper_from_dir\n",
    "from cam_utils import reshape_transform\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingByFish_logger = init_logger(r\"Testing by fish\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `vit_b_16_PredByFish.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vit_b_16_PredByFish.yaml\", mode=\"r\") as f_reader:\n",
    "    config = yaml.load(f_reader, Loader=yaml.SafeLoader)\n",
    "\n",
    "batch_size        = config[\"test_opts\"][\"base\"][\"batch_size\"]\n",
    "debug_mode        = config[\"test_opts\"][\"debug_mode\"][\"enable\"]\n",
    "debug_rand_select = config[\"test_opts\"][\"debug_mode\"][\"rand_select\"]\n",
    "do_cam = config[\"cam\"][\"enable\"]\n",
    "colormap = cv2.COLORMAP_JET # TODO: mapping dict for config \n",
    "\n",
    "load_dir_root = config[\"model\"][\"history_root\"]\n",
    "model_name    = config[\"model\"][\"model_name\"]\n",
    "model_history = config[\"model\"][\"history\"]\n",
    "model_desc    = config[\"model\"][\"desc\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `train_config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join(load_dir_root, model_name, model_history)\n",
    "train_config_path = os.path.join(load_dir, r\"train_config.yaml\")\n",
    "\n",
    "with open(train_config_path, mode=\"r\") as f_reader:\n",
    "    train_config = yaml.load(f_reader, Loader=yaml.SafeLoader)\n",
    "\n",
    "dataset_root = os.path.normpath(train_config[\"dataset\"][\"root\"])\n",
    "dataset_name = train_config[\"dataset\"][\"name\"]\n",
    "dataset_gen_method = train_config[\"dataset\"][\"gen_method\"]\n",
    "dataset_param_name = train_config[\"dataset\"][\"param_name\"]\n",
    "\n",
    "rand_seed         = train_config[\"train_opts\"][\"random_seed\"]\n",
    "cuda_idx          = train_config[\"train_opts\"][\"cuda\"][\"index\"]\n",
    "use_hsv           = train_config[\"train_opts\"][\"data\"][\"use_hsv\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `dataset_config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(dataset_root, dataset_name, dataset_gen_method, dataset_param_name)\n",
    "dataset_config_path = os.path.join(dataset_dir, \"dataset_config.yaml\")\n",
    "\n",
    "with open(dataset_config_path, mode=\"r\") as f_reader:\n",
    "    dataset_config = yaml.load(f_reader, Loader=yaml.SafeLoader)\n",
    "\n",
    "crop_size = dataset_config[\"gen_param\"][\"crop_size\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate `path_vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected_dir = os.path.join(dataset_dir, \"test\", \"selected\")\n",
    "cam_result_root = os.path.join(load_dir, \"cam_result\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-04-20 02:15:58,708 | Testing by fish | INFO | Using 'cuda', device_name = 'NVIDIA GeForce RTX 2080 Ti'\n",
      "| 2023-04-20 02:15:58,710 | Testing by fish | INFO | num2class_list = ['L', 'M', 'S'], class2num_dict = {'L': 0, 'M': 1, 'S': 2}\n",
      "| 2023-04-20 02:15:58,728 | Testing by fish | INFO | total = 1980\n",
      "| 2023-04-20 02:15:58,730 | Testing by fish | INFO | test_data (1980)\n",
      "| 2023-04-20 02:15:58,730 | Testing by fish | INFO | 0 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_0.tiff\n",
      "| 2023-04-20 02:15:58,730 | Testing by fish | INFO | 1 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_1.tiff\n",
      "| 2023-04-20 02:15:58,731 | Testing by fish | INFO | 2 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_2.tiff\n",
      "| 2023-04-20 02:15:58,731 | Testing by fish | INFO | 3 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_3.tiff\n",
      "| 2023-04-20 02:15:58,731 | Testing by fish | INFO | 4 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_4.tiff\n",
      "| 2023-04-20 02:15:58,732 | Testing by fish | INFO | ※ : total test batches: 124\n",
      "| 2023-04-20 02:15:58,733 | Testing by fish | INFO | load model using 'torch.hub.load()', model_name: 'vit_b_16', weights: 'vit_b_16/20230403_03_01_49_{EarlyStop}_{84_epochs_AugOnFly}/best_model.pth'\n",
      "Using cache found in C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1913a5faaa8a47ec8c06be08388932e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test :   0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-04-20 02:16:17,366 | Testing by fish | INFO | Batch[ 001 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:16:31,536 | Testing by fish | INFO | Batch[ 002 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:16:45,476 | Testing by fish | INFO | Batch[ 003 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:16:59,632 | Testing by fish | INFO | Batch[ 004 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:17:13,822 | Testing by fish | INFO | Batch[ 005 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:17:28,290 | Testing by fish | INFO | Batch[ 006 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:17:42,592 | Testing by fish | INFO | Batch[ 007 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:17:56,785 | Testing by fish | INFO | Batch[ 008 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:18:11,081 | Testing by fish | INFO | Batch[ 009 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:18:25,293 | Testing by fish | INFO | Batch[ 010 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:18:39,447 | Testing by fish | INFO | Batch[ 011 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:18:53,694 | Testing by fish | INFO | Batch[ 012 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:19:07,945 | Testing by fish | INFO | Batch[ 013 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:19:22,035 | Testing by fish | INFO | Batch[ 014 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:19:36,141 | Testing by fish | INFO | Batch[ 015 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:19:50,373 | Testing by fish | INFO | Batch[ 016 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:20:04,629 | Testing by fish | INFO | Batch[ 017 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:20:18,772 | Testing by fish | INFO | Batch[ 018 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:20:32,925 | Testing by fish | INFO | Batch[ 019 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:20:47,093 | Testing by fish | INFO | Batch[ 020 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:21:01,301 | Testing by fish | INFO | Batch[ 021 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:21:15,639 | Testing by fish | INFO | Batch[ 022 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:21:29,829 | Testing by fish | INFO | Batch[ 023 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:21:44,630 | Testing by fish | INFO | Batch[ 024 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:21:59,537 | Testing by fish | INFO | Batch[ 025 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:22:14,437 | Testing by fish | INFO | Batch[ 026 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:22:29,367 | Testing by fish | INFO | Batch[ 027 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:22:44,260 | Testing by fish | INFO | Batch[ 028 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:22:59,093 | Testing by fish | INFO | Batch[ 029 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:23:14,049 | Testing by fish | INFO | Batch[ 030 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:23:29,014 | Testing by fish | INFO | Batch[ 031 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:23:44,011 | Testing by fish | INFO | Batch[ 032 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:23:58,960 | Testing by fish | INFO | Batch[ 033 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:24:14,045 | Testing by fish | INFO | Batch[ 034 / 124 ], # of (ground truth == prediction) in this batch : 10/16\n",
      "| 2023-04-20 02:24:28,940 | Testing by fish | INFO | Batch[ 035 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:24:44,016 | Testing by fish | INFO | Batch[ 036 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:24:59,115 | Testing by fish | INFO | Batch[ 037 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:25:14,171 | Testing by fish | INFO | Batch[ 038 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:25:29,036 | Testing by fish | INFO | Batch[ 039 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:25:43,860 | Testing by fish | INFO | Batch[ 040 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:25:58,613 | Testing by fish | INFO | Batch[ 041 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:26:13,390 | Testing by fish | INFO | Batch[ 042 / 124 ], # of (ground truth == prediction) in this batch :  6/16\n",
      "| 2023-04-20 02:26:28,130 | Testing by fish | INFO | Batch[ 043 / 124 ], # of (ground truth == prediction) in this batch :  6/16\n",
      "| 2023-04-20 02:26:42,876 | Testing by fish | INFO | Batch[ 044 / 124 ], # of (ground truth == prediction) in this batch :  6/16\n",
      "| 2023-04-20 02:26:57,630 | Testing by fish | INFO | Batch[ 045 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:27:12,561 | Testing by fish | INFO | Batch[ 046 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:27:27,400 | Testing by fish | INFO | Batch[ 047 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:27:42,335 | Testing by fish | INFO | Batch[ 048 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:27:57,089 | Testing by fish | INFO | Batch[ 049 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:28:11,553 | Testing by fish | INFO | Batch[ 050 / 124 ], # of (ground truth == prediction) in this batch :  8/16\n",
      "| 2023-04-20 02:28:25,719 | Testing by fish | INFO | Batch[ 051 / 124 ], # of (ground truth == prediction) in this batch :  7/16\n",
      "| 2023-04-20 02:28:40,087 | Testing by fish | INFO | Batch[ 052 / 124 ], # of (ground truth == prediction) in this batch : 11/16\n",
      "| 2023-04-20 02:28:54,235 | Testing by fish | INFO | Batch[ 053 / 124 ], # of (ground truth == prediction) in this batch :  9/16\n",
      "| 2023-04-20 02:29:08,537 | Testing by fish | INFO | Batch[ 054 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:29:23,220 | Testing by fish | INFO | Batch[ 055 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:29:38,318 | Testing by fish | INFO | Batch[ 056 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:29:52,976 | Testing by fish | INFO | Batch[ 057 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:30:07,431 | Testing by fish | INFO | Batch[ 058 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:30:23,288 | Testing by fish | INFO | Batch[ 059 / 124 ], # of (ground truth == prediction) in this batch :  5/16\n",
      "| 2023-04-20 02:30:37,974 | Testing by fish | INFO | Batch[ 060 / 124 ], # of (ground truth == prediction) in this batch : 11/16\n",
      "| 2023-04-20 02:30:52,541 | Testing by fish | INFO | Batch[ 061 / 124 ], # of (ground truth == prediction) in this batch :  9/16\n",
      "| 2023-04-20 02:31:07,154 | Testing by fish | INFO | Batch[ 062 / 124 ], # of (ground truth == prediction) in this batch :  4/16\n",
      "| 2023-04-20 02:31:21,731 | Testing by fish | INFO | Batch[ 063 / 124 ], # of (ground truth == prediction) in this batch :  7/16\n",
      "| 2023-04-20 02:31:36,354 | Testing by fish | INFO | Batch[ 064 / 124 ], # of (ground truth == prediction) in this batch : 12/16\n",
      "| 2023-04-20 02:31:50,835 | Testing by fish | INFO | Batch[ 065 / 124 ], # of (ground truth == prediction) in this batch :  3/16\n",
      "| 2023-04-20 02:32:05,106 | Testing by fish | INFO | Batch[ 066 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:32:19,477 | Testing by fish | INFO | Batch[ 067 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:32:33,561 | Testing by fish | INFO | Batch[ 068 / 124 ], # of (ground truth == prediction) in this batch :  8/16\n",
      "| 2023-04-20 02:32:47,686 | Testing by fish | INFO | Batch[ 069 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:33:01,862 | Testing by fish | INFO | Batch[ 070 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:33:15,964 | Testing by fish | INFO | Batch[ 071 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:33:30,087 | Testing by fish | INFO | Batch[ 072 / 124 ], # of (ground truth == prediction) in this batch :  9/16\n",
      "| 2023-04-20 02:33:44,327 | Testing by fish | INFO | Batch[ 073 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:33:58,668 | Testing by fish | INFO | Batch[ 074 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:34:12,775 | Testing by fish | INFO | Batch[ 075 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:34:26,902 | Testing by fish | INFO | Batch[ 076 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:34:40,884 | Testing by fish | INFO | Batch[ 077 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:34:55,116 | Testing by fish | INFO | Batch[ 078 / 124 ], # of (ground truth == prediction) in this batch : 12/16\n",
      "| 2023-04-20 02:35:09,361 | Testing by fish | INFO | Batch[ 079 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:35:23,376 | Testing by fish | INFO | Batch[ 080 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:35:37,495 | Testing by fish | INFO | Batch[ 081 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:35:51,614 | Testing by fish | INFO | Batch[ 082 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:36:05,788 | Testing by fish | INFO | Batch[ 083 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:36:19,972 | Testing by fish | INFO | Batch[ 084 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:36:34,064 | Testing by fish | INFO | Batch[ 085 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:36:48,257 | Testing by fish | INFO | Batch[ 086 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:37:02,451 | Testing by fish | INFO | Batch[ 087 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:37:16,659 | Testing by fish | INFO | Batch[ 088 / 124 ], # of (ground truth == prediction) in this batch : 10/16\n",
      "| 2023-04-20 02:37:30,775 | Testing by fish | INFO | Batch[ 089 / 124 ], # of (ground truth == prediction) in this batch : 11/16\n",
      "| 2023-04-20 02:37:44,796 | Testing by fish | INFO | Batch[ 090 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:37:58,887 | Testing by fish | INFO | Batch[ 091 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:38:13,110 | Testing by fish | INFO | Batch[ 092 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:38:27,304 | Testing by fish | INFO | Batch[ 093 / 124 ], # of (ground truth == prediction) in this batch : 12/16\n",
      "| 2023-04-20 02:38:41,512 | Testing by fish | INFO | Batch[ 094 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:38:55,609 | Testing by fish | INFO | Batch[ 095 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:39:09,926 | Testing by fish | INFO | Batch[ 096 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:39:24,041 | Testing by fish | INFO | Batch[ 097 / 124 ], # of (ground truth == prediction) in this batch : 12/16\n",
      "| 2023-04-20 02:39:38,025 | Testing by fish | INFO | Batch[ 098 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:39:52,122 | Testing by fish | INFO | Batch[ 099 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:40:06,219 | Testing by fish | INFO | Batch[ 100 / 124 ], # of (ground truth == prediction) in this batch : 11/16\n",
      "| 2023-04-20 02:40:20,265 | Testing by fish | INFO | Batch[ 101 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:40:34,388 | Testing by fish | INFO | Batch[ 102 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:40:48,568 | Testing by fish | INFO | Batch[ 103 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:41:02,812 | Testing by fish | INFO | Batch[ 104 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:41:16,961 | Testing by fish | INFO | Batch[ 105 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:41:31,108 | Testing by fish | INFO | Batch[ 106 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:41:45,024 | Testing by fish | INFO | Batch[ 107 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:41:59,043 | Testing by fish | INFO | Batch[ 108 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:42:13,060 | Testing by fish | INFO | Batch[ 109 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:42:27,047 | Testing by fish | INFO | Batch[ 110 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:42:41,126 | Testing by fish | INFO | Batch[ 111 / 124 ], # of (ground truth == prediction) in this batch : 12/16\n",
      "| 2023-04-20 02:42:55,486 | Testing by fish | INFO | Batch[ 112 / 124 ], # of (ground truth == prediction) in this batch : 16/16\n",
      "| 2023-04-20 02:43:10,303 | Testing by fish | INFO | Batch[ 113 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:43:24,404 | Testing by fish | INFO | Batch[ 114 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:43:38,613 | Testing by fish | INFO | Batch[ 115 / 124 ], # of (ground truth == prediction) in this batch :  6/16\n",
      "| 2023-04-20 02:43:52,951 | Testing by fish | INFO | Batch[ 116 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:44:07,392 | Testing by fish | INFO | Batch[ 117 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:44:21,675 | Testing by fish | INFO | Batch[ 118 / 124 ], # of (ground truth == prediction) in this batch :  9/16\n",
      "| 2023-04-20 02:44:36,001 | Testing by fish | INFO | Batch[ 119 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:44:50,356 | Testing by fish | INFO | Batch[ 120 / 124 ], # of (ground truth == prediction) in this batch : 15/16\n",
      "| 2023-04-20 02:45:04,510 | Testing by fish | INFO | Batch[ 121 / 124 ], # of (ground truth == prediction) in this batch : 13/16\n",
      "| 2023-04-20 02:45:18,798 | Testing by fish | INFO | Batch[ 122 / 124 ], # of (ground truth == prediction) in this batch : 14/16\n",
      "| 2023-04-20 02:45:32,885 | Testing by fish | INFO | Batch[ 123 / 124 ], # of (ground truth == prediction) in this batch :  7/16\n",
      "| 2023-04-20 02:45:43,139 | Testing by fish | INFO | Batch[ 124 / 124 ], # of (ground truth == prediction) in this batch :  0/12\n"
     ]
    }
   ],
   "source": [
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "testingByFish_logger.info(f\"Using '{device}', device_name = '{device_name}'\")\n",
    "\n",
    "\n",
    "# Get datetime\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "\n",
    "# Set 'np.random.seed'\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_mapper'\n",
    "num2class_list, class2num_dict = get_sortedClassMapper_from_dir(test_selected_dir)\n",
    "testingByFish_logger.info(f\"num2class_list = {num2class_list}, class2num_dict = {class2num_dict}\")\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "test_img_list = glob(os.path.normpath(f\"{test_selected_dir}/*/*.tiff\"))\n",
    "testingByFish_logger.info(f\"total = {len(test_img_list)}\")\n",
    "## debug mode: random select [debug_rand_select] images\n",
    "if debug_mode:\n",
    "    test_img_list = np.random.choice(test_img_list, size=debug_rand_select, replace=False)\n",
    "    testingByFish_logger.info(f\"Debug mode, only select first {len(test_img_list)}\")\n",
    "\n",
    "\n",
    "# Save 'testing_amount'\n",
    "testing_amount = f\"{{ datatest_{len(test_img_list)} }}_{{ test_{len(test_img_list)} }}\"\n",
    "with open(os.path.normpath(f\"{load_dir}/{testing_amount}\"), mode=\"w\") as f_writer: pass\n",
    "\n",
    "\n",
    "# Create 'test_set', 'test_dataloader'\n",
    "testingByFish_logger.info(f\"test_data ({len(test_img_list)})\")\n",
    "[testingByFish_logger.info(f\"{i} : img_path = {test_img_list[i]}\") for i in range(5)]\n",
    "test_set = ImgDataset(test_img_list, class_mapper=class2num_dict, resize=(224, 224), \n",
    "                      use_hsv=use_hsv)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "testingByFish_logger.info(f\"※ : total test batches: {len(test_dataloader)}\")\n",
    "\n",
    "\n",
    "# Read test ( debug mode only )\n",
    "if debug_mode:\n",
    "    read_test = cv2.imread(test_img_list[-1])\n",
    "    testingByFish_logger.info(f\"Read Test: {test_img_list[-1]}\")\n",
    "    cv2.imshow(\"Read Test\", read_test)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Create model\n",
    "testingByFish_logger.info((f\"load model using 'torch.hub.load()', \"\n",
    "                     f\"model_name: '{model_name}', weights: '{model_name}/{model_history}/{model_desc}_model.pth'\"))\n",
    "model = torch.hub.load('pytorch/vision', model_name, weights=None)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class2num_dict), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "## load 'model_state_dict'\n",
    "model_path = os.path.join(load_dir, f\"{model_desc}_model.pth\")\n",
    "pth_file = torch.load(model_path, map_location=device) # unpack to device directly\n",
    "model.load_state_dict(pth_file[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "\"\"\" Initial 'CAM' generator\n",
    "\n",
    "    (ref) github: https://github.com/jacobgil/pytorch-grad-cam\n",
    "\n",
    "    (ref) vit_example: https://github.com/jacobgil/pytorch-grad-cam/blob/2183a9cbc1bd5fc1d8e134b4f3318c3b6db5671f/usage_examples/vit_example.py\n",
    "\n",
    "    Explaination: https://jacobgil.github.io/pytorch-gradcam-book/vision_transformers.html#how-does-it-work-with-vision-transformers\n",
    "\n",
    "    1. 使用 torch.hub.load('facebookresearch/deit:main','deit_tiny_patch16_224', pretrained=True) 時 target_layers = [model.blocks[-1].norm1]\n",
    "    2. 透過 print(model) 比較後 torch.hub.load('pytorch/vision', vit_b_16, weights=None) 應使用 target_layers = [model.encoder.layers.encoder_layer_10.ln_1]\n",
    "\n",
    "\"\"\"\n",
    "if do_cam:\n",
    "    target_layers = [model.encoder.layers.encoder_layer_10.ln_1]\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True, reshape_transform=reshape_transform)\n",
    "    cam.batch_size = batch_size\n",
    "\n",
    "\n",
    "# Testing\n",
    "## testing variable\n",
    "test_log = { \"Test\": time_stamp, \"model_desc\": f\"{model_desc}_model.pth\" }\n",
    "fish_gt_dict = {}\n",
    "fish_predcnt_dict = {}\n",
    "image_predict_ans_dict = {}\n",
    "## progress bar\n",
    "pbar_n_test = tqdm(total=len(test_dataloader), desc=\"Test \")\n",
    "## start testing\n",
    "## set to evaluation mode\n",
    "model.eval()\n",
    "for batch, data in enumerate(test_dataloader):\n",
    "    x_test, y_test, crop_name_batch = data\n",
    "    x_test, y_test = x_test.to(device), y_test.to(device) # move to GPU\n",
    "    preds = model(x_test)\n",
    "    _, pred_test = torch.max(preds, 1)\n",
    "    \n",
    "    \n",
    "    ## generate 'CAM' heatmap\n",
    "    ### 'ImgDataset' converts the 'img_dims' to the format required by the model, so it needs to be converted back.\n",
    "    ### usage: np.moveaxis([ batch_size, C, H, W ] , 1, -1) --> [ batch_size, H, W, C ]\n",
    "    if do_cam:\n",
    "        targets = None # If None, returns the map for the highest scoring category. Otherwise, targets the requested category.\n",
    "        grayscale_cam_batch = cam(input_tensor=x_test, targets=targets, aug_smooth=True, eigen_smooth=True)\n",
    "        rgb_img_batch = np.moveaxis(deepcopy(x_test).cpu().numpy(), 1, -1)\n",
    "    \n",
    "    \n",
    "    ## update 'predict_class' according to 'fish_name'\n",
    "    pred_test_list = pred_test.cpu().numpy().tolist()\n",
    "    for i, crop_name in enumerate(crop_name_batch):\n",
    "        \n",
    "        ### update 'fish_gt_dict'\n",
    "        crop_name_list = crop_name.split(\"_\")\n",
    "        fish_name = \"_\".join(crop_name_list[:4]) # example_list : ['L', 'fish', '111', 'A', 'selected', '0']\n",
    "                                                 # list[:3] = L_fish_111 ; list[:4] = L_fish_111_A\n",
    "        if fish_name not in fish_gt_dict: fish_gt_dict[fish_name] = crop_name_list[0]\n",
    "        \n",
    "        ### update 'fish_predcnt_dict'\n",
    "        if fish_name not in fish_predcnt_dict: fish_predcnt_dict[fish_name] = Counter()\n",
    "        fish_predcnt_dict[fish_name].update([num2class_list[pred_test_list[i]]])\n",
    "        \n",
    "        ### store each crop image prediction result in `dict` ( for visualization )\n",
    "        image_predict_ans_dict[crop_name] = { \"gt\": crop_name_list[0],\n",
    "                                              \"pred\": num2class_list[pred_test_list[i]] }\n",
    "        \n",
    "        ### save cam result ( grayscale, colormap )\n",
    "        if do_cam:\n",
    "            \n",
    "            cam_result_dir = os.path.join(cam_result_root, fish_name, \"grayscale_map\")\n",
    "            create_new_dir(cam_result_dir, display_in_CLI=False)\n",
    "            crop_name_list[4] = \"graymap\"\n",
    "            cam_save_path = os.path.normpath(f\"{cam_result_dir}/{'_'.join(crop_name_list)}.tiff\")\n",
    "            grayscale_cam = np.uint8(255 * grayscale_cam_batch[i, :])\n",
    "            cv2.imwrite(cam_save_path, cv2.resize(grayscale_cam, (crop_size, crop_size),\n",
    "                                                  interpolation=cv2.INTER_CUBIC))\n",
    "            \n",
    "            cam_result_dir = os.path.join(cam_result_root, fish_name, \"color_map\")\n",
    "            create_new_dir(cam_result_dir, display_in_CLI=False)\n",
    "            crop_name_list[4] = \"colormap\"\n",
    "            cam_save_path = os.path.normpath(f\"{cam_result_dir}/{'_'.join(crop_name_list)}.tiff\")\n",
    "            colormap_cam = cv2.applyColorMap(grayscale_cam, colormap) # BGR\n",
    "            cv2.imwrite(cam_save_path, cv2.resize(colormap_cam, (crop_size, crop_size),\n",
    "                                                  interpolation=cv2.INTER_CUBIC))\n",
    "            \n",
    "    \n",
    "    \n",
    "    ## show predict_status of current_batch in CLI\n",
    "    testingByFish_logger.info((f\"Batch[ {(batch+1):0{len(str(len(test_dataloader)))}} / {len(test_dataloader)} ], \"\n",
    "                               f\"# of (ground truth == prediction) in this batch : \"\n",
    "                               f\"{(pred_test.cpu() == y_test.cpu()).sum().item():{len(str(len(y_test)))}}/{len(y_test)}\"))\n",
    "    \n",
    "    ## update 'pbar_n_test'\n",
    "    pbar_n_test.update(1)\n",
    "    pbar_n_test.refresh()\n",
    "\n",
    "pbar_n_test.close()\n",
    "## end testing\n",
    "\n",
    "\n",
    "for key, value in fish_predcnt_dict.items(): fish_predcnt_dict[key] = value.most_common(1)[0][0]\n",
    "pred_list_to_name = [ value for _, value in fish_predcnt_dict.items() ]\n",
    "gt_list_to_name = [ value for _, value in fish_gt_dict.items() ]\n",
    "\n",
    "caulculate_metrics(test_log, None,\n",
    "                   gt_list_to_name, pred_list_to_name, class2num_dict)\n",
    "# print(json.dumps(test_log, indent=4))\n",
    "\n",
    "\n",
    "# Save `image_predict_ans_dict`\n",
    "with open(os.path.normpath(f\"{cam_result_root}/{{Logs}}_predict_ans.log\"), mode=\"w\") as f_writer:\n",
    "    f_writer.write(json.dumps(image_predict_ans_dict, indent=4))\n",
    "\n",
    "\n",
    "# Save infomations to a file\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Logs}}_test.log\"), mode=\"w\") as f_writer:\n",
    "\n",
    "    ## change direction of 'sys.stdout'\n",
    "    orig_stdout = sys.stdout # store original 'sys.stdout'\n",
    "    sys.stdout = f_writer\n",
    "\n",
    "    ## write 'test_log'\n",
    "    print(json.dumps(test_log, indent=4), \"\\n\\n\")\n",
    "\n",
    "    ## write 'classification_report'\n",
    "    cls_report = classification_report(y_true=gt_list_to_name, y_pred=pred_list_to_name)\n",
    "    print(\"Classification Report:\\n\\n\", cls_report, \"\\n\")\n",
    "\n",
    "    ## write 'confusion_matrix'\n",
    "    #   row: Ground truth\n",
    "    #   column: predict\n",
    "    #  *　0　1　2\n",
    "    #  0 [] [] []\n",
    "    #  1 [] [] []\n",
    "    #  2 [] [] []\n",
    "    #\n",
    "    confusion_mat = confusion_matrix_with_class(ground_truth=gt_list_to_name, prediction=pred_list_to_name)\n",
    "\n",
    "    ## recover direct of 'sys.stdout'\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "\n",
    "# Rename 'load_dir'\n",
    "## new_name_format = {time_stamp}_{state}_{target_epochs_with_ImgLoadOptions}_{test_f1}\n",
    "## state = {EarlyStop, Interrupt, Completed, Tested, etc.}\n",
    "model_history_list = re.split(\"{|}\", model_history)\n",
    "new_name = f\"{model_history_list[0]}{{Tested}}_{{{model_history_list[3]}}}_{{{model_desc}}}_{{avg_f1_{test_log['average_f1']}}}\" \n",
    "os.rename(load_dir, os.path.join(load_dir_root, model_name, new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae46fe3be2f97d3a16702042bc6c7abd422dd0bfb5ce5527ad30c3a287e1c756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
