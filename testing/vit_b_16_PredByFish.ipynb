{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for ```Testing```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import traceback\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import argparse\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\confocal_microscope\\Desktop\\ZebraFish_AP_POS\\modules\") # add path to scan customized module\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend, \\\n",
    "                     confusion_matrix_with_class, get_sortedClassMapper_from_dir\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingByFish_logger = init_logger(r\"Testing by fish\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_data_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Temp}_Data\"\n",
    "ap_dataset_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\"\n",
    "load_dir_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test_by_fish}_Model_history\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-04-03 18:38:04,798 | Testing by fish | INFO | Using 'cuda', device_name = 'NVIDIA GeForce RTX 2080 Ti'\n"
     ]
    }
   ],
   "source": [
    "dataset_name = r\"{20230305_NEW_STRUCT}_Academia_Sinica_i409\"\n",
    "dataset_gen_method = \"fish_dataset_horiz_cut_1l2_Mix_AP\"\n",
    "dataset_param_name = \"DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\"\n",
    "cuda_idx = 1\n",
    "label_in_filename = 0\n",
    "batch_size = 32\n",
    "model_name = \"vit_b_16\"\n",
    "model_history = r\"20230403_03_01_49_{EarlyStop}_{84_epochs_AugOnFly}\"\n",
    "model_desc = \"best\" # best / final\n",
    "use_hsv = False # using 'HSV' when getting images from the 'ImgDataset'\n",
    "\n",
    "debug_mode = False\n",
    "rand_seed = 2022 # only for debug_mode\n",
    "\n",
    "\n",
    "# vars for 'PredByFish'\n",
    "data_name = r\"{20230305_NEW_STRUCT}_Academia_Sinica_i409\"\n",
    "xlsx_file = r\"{3CLS_BY_SurfStDev}_data.xlsx\"\n",
    "sheet_name = \"3C 0.5DEV\"\n",
    "xlsx_file_fullpath = os.path.join(ap_data_root, data_name, r\"{Modify}_xlsx\", xlsx_file)\n",
    "df_input_xlsx :pd.DataFrame = pd.read_excel(xlsx_file_fullpath, engine = 'openpyxl', sheet_name=sheet_name)\n",
    "df_Analysis_list = df_input_xlsx[\"BrightField name with Analysis statement (CSV)\"].tolist()\n",
    "df_class_list = df_input_xlsx[\"class\"].tolist()\n",
    "assert len(df_Analysis_list) == len(df_class_list), \"Excel file content error: len(df_Analysis_list) != len(df_class_list)\"\n",
    "fishid2class_dict = {}\n",
    "fishpredcnt_dict = {}\n",
    "for i in range(len(df_Analysis_list)):\n",
    "    fish_name_list = re.split(\" |_|-\", df_Analysis_list[i])\n",
    "    fish_ID = fish_name_list[8]\n",
    "    fishid2class_dict[fish_ID] = df_class_list[i]\n",
    "    fishpredcnt_dict[fish_ID] = Counter()\n",
    "\n",
    "\n",
    "# Create path var\n",
    "load_dir = os.path.join(load_dir_root, model_name, model_history)\n",
    "test_selected_dir = os.path.join(ap_dataset_root, dataset_name, dataset_gen_method, dataset_param_name, \"test\", \"selected\")\n",
    "\n",
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "testingByFish_logger.info(f\"Using '{device}', device_name = '{device_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-04-03 18:38:04,850 | Testing by fish | INFO | num2class_list = ['L', 'M', 'S'], class2num_dict = {'L': 0, 'M': 1, 'S': 2}\n",
      "| 2023-04-03 18:38:04,870 | Testing by fish | INFO | total = 1980\n",
      "| 2023-04-03 18:38:04,872 | Testing by fish | INFO | test_data (1980)\n",
      "| 2023-04-03 18:38:04,872 | Testing by fish | INFO | 0 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_0.tiff\n",
      "| 2023-04-03 18:38:04,873 | Testing by fish | INFO | 1 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_1.tiff\n",
      "| 2023-04-03 18:38:04,874 | Testing by fish | INFO | 2 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_2.tiff\n",
      "| 2023-04-03 18:38:04,874 | Testing by fish | INFO | 3 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_3.tiff\n",
      "| 2023-04-03 18:38:04,874 | Testing by fish | INFO | 4 : img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_111_A_selected_4.tiff\n",
      "| 2023-04-03 18:38:04,875 | Testing by fish | INFO | ※ : total test batches: 62\n",
      "| 2023-04-03 18:38:04,876 | Testing by fish | INFO | load model using 'torch.hub.load()', model_name: 'vit_b_16', weights: 'vit_b_16/20230403_03_01_49_{EarlyStop}_{84_epochs_AugOnFly}/best_model.pth'\n",
      "Using cache found in C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\n",
      "C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abaf840372bf413587c0da5d334a3403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test :   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-04-03 18:38:10,082 | Testing by fish | INFO | Batch[ 01 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:10,415 | Testing by fish | INFO | Batch[ 02 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:10,729 | Testing by fish | INFO | Batch[ 03 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:11,048 | Testing by fish | INFO | Batch[ 04 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:11,362 | Testing by fish | INFO | Batch[ 05 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:11,682 | Testing by fish | INFO | Batch[ 06 / 62 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-04-03 18:38:11,997 | Testing by fish | INFO | Batch[ 07 / 62 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-04-03 18:38:12,306 | Testing by fish | INFO | Batch[ 08 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:12,631 | Testing by fish | INFO | Batch[ 09 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:12,947 | Testing by fish | INFO | Batch[ 10 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:13,268 | Testing by fish | INFO | Batch[ 11 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:13,588 | Testing by fish | INFO | Batch[ 12 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:13,898 | Testing by fish | INFO | Batch[ 13 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:14,205 | Testing by fish | INFO | Batch[ 14 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:14,528 | Testing by fish | INFO | Batch[ 15 / 62 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-04-03 18:38:14,847 | Testing by fish | INFO | Batch[ 16 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:15,176 | Testing by fish | INFO | Batch[ 17 / 62 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-04-03 18:38:15,507 | Testing by fish | INFO | Batch[ 18 / 62 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-04-03 18:38:15,815 | Testing by fish | INFO | Batch[ 19 / 62 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-04-03 18:38:16,137 | Testing by fish | INFO | Batch[ 20 / 62 ], # of (ground truth == prediction) in_this_batch： 27/32\n",
      "| 2023-04-03 18:38:16,458 | Testing by fish | INFO | Batch[ 21 / 62 ], # of (ground truth == prediction) in_this_batch： 22/32\n",
      "| 2023-04-03 18:38:16,771 | Testing by fish | INFO | Batch[ 22 / 62 ], # of (ground truth == prediction) in_this_batch： 12/32\n",
      "| 2023-04-03 18:38:17,089 | Testing by fish | INFO | Batch[ 23 / 62 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-04-03 18:38:17,411 | Testing by fish | INFO | Batch[ 24 / 62 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-04-03 18:38:17,737 | Testing by fish | INFO | Batch[ 25 / 62 ], # of (ground truth == prediction) in_this_batch： 24/32\n",
      "| 2023-04-03 18:38:18,059 | Testing by fish | INFO | Batch[ 26 / 62 ], # of (ground truth == prediction) in_this_batch： 18/32\n",
      "| 2023-04-03 18:38:18,373 | Testing by fish | INFO | Batch[ 27 / 62 ], # of (ground truth == prediction) in_this_batch： 25/32\n",
      "| 2023-04-03 18:38:18,693 | Testing by fish | INFO | Batch[ 28 / 62 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-04-03 18:38:19,022 | Testing by fish | INFO | Batch[ 29 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:19,356 | Testing by fish | INFO | Batch[ 30 / 62 ], # of (ground truth == prediction) in_this_batch： 16/32\n",
      "| 2023-04-03 18:38:19,689 | Testing by fish | INFO | Batch[ 31 / 62 ], # of (ground truth == prediction) in_this_batch： 13/32\n",
      "| 2023-04-03 18:38:20,013 | Testing by fish | INFO | Batch[ 32 / 62 ], # of (ground truth == prediction) in_this_batch： 19/32\n",
      "| 2023-04-03 18:38:20,338 | Testing by fish | INFO | Batch[ 33 / 62 ], # of (ground truth == prediction) in_this_batch： 18/32\n",
      "| 2023-04-03 18:38:20,666 | Testing by fish | INFO | Batch[ 34 / 62 ], # of (ground truth == prediction) in_this_batch： 22/32\n",
      "| 2023-04-03 18:38:20,994 | Testing by fish | INFO | Batch[ 35 / 62 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-04-03 18:38:21,334 | Testing by fish | INFO | Batch[ 36 / 62 ], # of (ground truth == prediction) in_this_batch： 25/32\n",
      "| 2023-04-03 18:38:21,673 | Testing by fish | INFO | Batch[ 37 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:21,985 | Testing by fish | INFO | Batch[ 38 / 62 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-04-03 18:38:22,301 | Testing by fish | INFO | Batch[ 39 / 62 ], # of (ground truth == prediction) in_this_batch： 25/32\n",
      "| 2023-04-03 18:38:22,619 | Testing by fish | INFO | Batch[ 40 / 62 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-04-03 18:38:22,931 | Testing by fish | INFO | Batch[ 41 / 62 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-04-03 18:38:23,252 | Testing by fish | INFO | Batch[ 42 / 62 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-04-03 18:38:23,576 | Testing by fish | INFO | Batch[ 43 / 62 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-04-03 18:38:23,896 | Testing by fish | INFO | Batch[ 44 / 62 ], # of (ground truth == prediction) in_this_batch： 25/32\n",
      "| 2023-04-03 18:38:24,209 | Testing by fish | INFO | Batch[ 45 / 62 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-04-03 18:38:24,526 | Testing by fish | INFO | Batch[ 46 / 62 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-04-03 18:38:24,848 | Testing by fish | INFO | Batch[ 47 / 62 ], # of (ground truth == prediction) in_this_batch： 25/32\n",
      "| 2023-04-03 18:38:25,161 | Testing by fish | INFO | Batch[ 48 / 62 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-04-03 18:38:25,489 | Testing by fish | INFO | Batch[ 49 / 62 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-04-03 18:38:25,812 | Testing by fish | INFO | Batch[ 50 / 62 ], # of (ground truth == prediction) in_this_batch： 25/32\n",
      "| 2023-04-03 18:38:26,143 | Testing by fish | INFO | Batch[ 51 / 62 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-04-03 18:38:26,458 | Testing by fish | INFO | Batch[ 52 / 62 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-04-03 18:38:26,778 | Testing by fish | INFO | Batch[ 53 / 62 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-04-03 18:38:27,104 | Testing by fish | INFO | Batch[ 54 / 62 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-04-03 18:38:27,431 | Testing by fish | INFO | Batch[ 55 / 62 ], # of (ground truth == prediction) in_this_batch： 27/32\n",
      "| 2023-04-03 18:38:27,747 | Testing by fish | INFO | Batch[ 56 / 62 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-04-03 18:38:28,072 | Testing by fish | INFO | Batch[ 57 / 62 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-04-03 18:38:28,392 | Testing by fish | INFO | Batch[ 58 / 62 ], # of (ground truth == prediction) in_this_batch： 20/32\n",
      "| 2023-04-03 18:38:28,708 | Testing by fish | INFO | Batch[ 59 / 62 ], # of (ground truth == prediction) in_this_batch： 23/32\n",
      "| 2023-04-03 18:38:29,026 | Testing by fish | INFO | Batch[ 60 / 62 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-04-03 18:38:29,339 | Testing by fish | INFO | Batch[ 61 / 62 ], # of (ground truth == prediction) in_this_batch： 27/32\n",
      "| 2023-04-03 18:38:29,616 | Testing by fish | INFO | Batch[ 62 / 62 ], # of (ground truth == prediction) in_this_batch：  7/28\n"
     ]
    }
   ],
   "source": [
    "# Get datetime\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "\n",
    "# Set 'np.random.seed'\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_mapper'\n",
    "num2class_list, class2num_dict = get_sortedClassMapper_from_dir(test_selected_dir)\n",
    "testingByFish_logger.info(f\"num2class_list = {num2class_list}, class2num_dict = {class2num_dict}\")\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "test_img_list = glob(os.path.normpath(f\"{test_selected_dir}/*/*.tiff\"))\n",
    "testingByFish_logger.info(f\"total = {len(test_img_list)}\")\n",
    "## debug mode: random select 200 images\n",
    "if debug_mode:\n",
    "    test_img_list = np.random.choice(test_img_list, size=200, replace=False)\n",
    "    testingByFish_logger.info(f\"Debug mode, only select first {len(test_img_list)}\")\n",
    "\n",
    "\n",
    "# Save 'testing_amount'\n",
    "testing_amount = f\"{{ datatest_{len(test_img_list)} }}_{{ test_{len(test_img_list)} }}\"\n",
    "with open(os.path.normpath(f\"{load_dir}/{testing_amount}\"), mode=\"w\") as f_writer: pass\n",
    "\n",
    "\n",
    "# Create 'test_set', 'test_dataloader'\n",
    "testingByFish_logger.info(f\"test_data ({len(test_img_list)})\")\n",
    "[testingByFish_logger.info(f\"{i} : img_path = {test_img_list[i]}\") for i in range(5)]\n",
    "test_set = ImgDataset(test_img_list, class_mapper=class2num_dict, label_in_filename=label_in_filename, \n",
    "                      use_hsv=use_hsv)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "testingByFish_logger.info(f\"※ : total test batches: {len(test_dataloader)}\")\n",
    "\n",
    "\n",
    "# Read test ( debug mode only )\n",
    "if debug_mode:\n",
    "    read_test = cv2.imread(test_img_list[-1])\n",
    "    testingByFish_logger.info(f\"Read Test: {test_img_list[-1]}\")\n",
    "    cv2.imshow(\"Read Test\", read_test)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Create model\n",
    "testingByFish_logger.info((f\"load model using 'torch.hub.load()', \"\n",
    "                     f\"model_name: '{model_name}', weights: '{model_name}/{model_history}/{model_desc}_model.pth'\"))\n",
    "model = torch.hub.load('pytorch/vision', model_name, weights=None)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class2num_dict), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "## load 'model_state_dict'\n",
    "model_path = os.path.join(load_dir, f\"{model_desc}_model.pth\")\n",
    "pth_file = torch.load(model_path, map_location=device) # unpack to device directly\n",
    "model.load_state_dict(pth_file[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "# Testing\n",
    "## testing variable\n",
    "test_log = { \"Test\": time_stamp, \"model_desc\": f\"{model_desc}_model.pth\" }\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "## progress bar\n",
    "pbar_n_test = tqdm(total=len(test_dataloader), desc=\"Test \")\n",
    "## start testing\n",
    "## set to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        x_test, y_test, fish_ID_list = data\n",
    "        x_test, y_test = x_test.to(device), y_test.to(device) # move to GPU\n",
    "        preds = model(x_test)\n",
    "        _, pred_test = torch.max(preds, 1)\n",
    "        \n",
    "        ## append predictions according to 'fish_ID'\n",
    "        pred_test_list = pred_test.cpu().numpy().tolist()\n",
    "        for i in range(len(pred_test_list)): fishpredcnt_dict[fish_ID_list[i]].update([pred_test_list[i]])\n",
    "        \n",
    "        \n",
    "        ## show predict_status of current_batch in CLI\n",
    "        testingByFish_logger.info((f\"Batch[ {(batch+1):0{len(str(len(test_dataloader)))}} / {len(test_dataloader)} ], \"\n",
    "                                   f\"# of (ground truth == prediction) in_this_batch： \"\n",
    "                                   f\"{(pred_test.cpu() == y_test.cpu()).sum().item():{len(str(len(y_test)))}}/{len(y_test)}\"))\n",
    "        \n",
    "        ## update 'pbar_n_test'\n",
    "        pbar_n_test.update(1)\n",
    "        pbar_n_test.refresh()\n",
    "\n",
    "\n",
    "for key, value in fishpredcnt_dict.items(): fishpredcnt_dict[key] = value.most_common(1)[0][0]\n",
    "pred_list = [ num2class_list[value] for _, value in fishpredcnt_dict.items() ]\n",
    "gt_list = [ class2num_dict[value] for _, value in fishid2class_dict.items() ]\n",
    "caulculate_metrics(test_log, None,\n",
    "                   gt_list, pred_list, class2num_dict)\n",
    "# print(json.dumps(test_log, indent=4))\n",
    "pbar_n_test.close()\n",
    "## end testing\n",
    "\n",
    "\n",
    "# Save infomations to a file\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Logs}}_test.log\"), mode=\"w\") as f_writer:\n",
    "\n",
    "    ## change direction of 'sys.stdout'\n",
    "    orig_stdout = sys.stdout # store original 'sys.stdout'\n",
    "    sys.stdout = f_writer\n",
    "\n",
    "    ## write 'test_log'\n",
    "    print(json.dumps(test_log, indent=4), \"\\n\\n\")\n",
    "\n",
    "    ## write 'classification_report'\n",
    "    gt_list_to_name = [ num2class_list[i] for i in gt_list ]\n",
    "    pred_list_to_name = [ num2class_list[i] for i in pred_list ]\n",
    "    cls_report = classification_report(y_true=gt_list_to_name, y_pred=pred_list_to_name)\n",
    "    print(\"Classification Report:\\n\\n\", cls_report, \"\\n\")\n",
    "\n",
    "    ## write 'confusion_matrix'\n",
    "    #   row: Ground truth\n",
    "    #   column: predict\n",
    "    #  *　0　1　2\n",
    "    #  0 [] [] []\n",
    "    #  1 [] [] []\n",
    "    #  2 [] [] []\n",
    "    #\n",
    "    confusion_mat = confusion_matrix_with_class(ground_truth=gt_list_to_name, prediction=pred_list_to_name)\n",
    "\n",
    "    ## recover direct of 'sys.stdout'\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "\n",
    "# Rename 'load_dir'\n",
    "## new_name_format = {time_stamp}_{state}_{target_epochs_with_ImgLoadOptions}_{test_f1}\n",
    "## state = {EarlyStop, Interrupt, Completed, Tested, etc.}\n",
    "model_history_list = re.split(\"{|}\", model_history)\n",
    "new_name = f\"{model_history_list[0]}{{Tested}}_{{{model_history_list[3]}}}_{{{model_desc}}}_{{avg_f1_{test_log['average_f1']}}}\" \n",
    "os.rename(load_dir, os.path.join(load_dir_root, model_name, new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae46fe3be2f97d3a16702042bc6c7abd422dd0bfb5ce5527ad30c3a287e1c756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
