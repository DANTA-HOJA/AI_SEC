{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for ```Testing```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import traceback\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "sys.path.append(\"/home/rime97410000/ZebraFish_Code/ZebraFish_AP_POS/modules\") # add path to scan customized module\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend, \\\n",
    "                     confusion_matrix_with_class, get_sortedClassMapper_from_dir\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingByImg_logger = init_logger(r\"Testing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `vit_b_16_PredByImg.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vit_b_16_PredByImg.yaml\", mode=\"r\") as f_reader:\n",
    "    config = yaml.load(f_reader, Loader=yaml.SafeLoader)\n",
    "    \n",
    "batch_size        = config[\"test_opts\"][\"base\"][\"batch_size\"]\n",
    "debug_mode        = config[\"test_opts\"][\"debug_mode\"][\"enable\"]\n",
    "debug_rand_select = config[\"test_opts\"][\"debug_mode\"][\"rand_select\"]\n",
    "\n",
    "load_dir_root = config[\"model\"][\"history_root\"]\n",
    "model_name    = config[\"model\"][\"model_name\"]\n",
    "model_history = config[\"model\"][\"history\"]\n",
    "model_desc    = config[\"model\"][\"desc\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `train_config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join(load_dir_root, model_name, model_history)\n",
    "train_config_path = os.path.join(load_dir, r\"train_config.yaml\")\n",
    "\n",
    "with open(train_config_path, mode=\"r\") as f_reader:\n",
    "    train_config = yaml.load(f_reader, Loader=yaml.SafeLoader)\n",
    "\n",
    "dataset_root       = os.path.normpath(train_config[\"dataset\"][\"root\"])\n",
    "dataset_name       = train_config[\"dataset\"][\"name\"]\n",
    "dataset_gen_method = train_config[\"dataset\"][\"gen_method\"]\n",
    "dataset_stdev      = train_config[\"dataset\"][\"stdev\"]\n",
    "dataset_param_name = train_config[\"dataset\"][\"param_name\"]\n",
    "\n",
    "rand_seed         = train_config[\"train_opts\"][\"random_seed\"]\n",
    "cuda_idx          = train_config[\"train_opts\"][\"cuda\"][\"index\"]\n",
    "use_hsv           = train_config[\"train_opts\"][\"data\"][\"use_hsv\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate `path_vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(dataset_root, dataset_name, dataset_gen_method, dataset_stdev, dataset_param_name)\n",
    "test_selected_dir = os.path.join(dataset_dir, \"test\", \"selected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-04-27 00:30:04,055 | Testing | INFO | Using 'cuda', device_name = 'NVIDIA GeForce RTX 4090'\n",
      "| 2023-04-27 00:30:04,055 | Testing | INFO | num2class_list = ['L', 'M', 'S'], class2num_dict = {'L': 0, 'M': 1, 'S': 2}\n",
      "| 2023-04-27 00:30:04,058 | Testing | INFO | total = 2460\n",
      "| 2023-04-27 00:30:04,058 | Testing | INFO | test_data (2460)\n",
      "| 2023-04-27 00:30:04,058 | Testing | INFO | 0 : img_path = /home/rime97410000/ZebraFish_DB/{Dataset}_Cropped/{20230424_Update}_Academia_Sinica_i505/fish_dataset_horiz_cut_1l2_Mix_AP/0.75_STDEV/DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022/test/selected/S/S_fish_132_P_selected_3.tiff\n",
      "| 2023-04-27 00:30:04,059 | Testing | INFO | 1 : img_path = /home/rime97410000/ZebraFish_DB/{Dataset}_Cropped/{20230424_Update}_Academia_Sinica_i505/fish_dataset_horiz_cut_1l2_Mix_AP/0.75_STDEV/DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022/test/selected/S/S_fish_135_A_selected_4.tiff\n",
      "| 2023-04-27 00:30:04,059 | Testing | INFO | 2 : img_path = /home/rime97410000/ZebraFish_DB/{Dataset}_Cropped/{20230424_Update}_Academia_Sinica_i505/fish_dataset_horiz_cut_1l2_Mix_AP/0.75_STDEV/DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022/test/selected/S/S_fish_16_P_selected_1.tiff\n",
      "| 2023-04-27 00:30:04,059 | Testing | INFO | 3 : img_path = /home/rime97410000/ZebraFish_DB/{Dataset}_Cropped/{20230424_Update}_Academia_Sinica_i505/fish_dataset_horiz_cut_1l2_Mix_AP/0.75_STDEV/DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022/test/selected/S/S_fish_25_P_selected_0.tiff\n",
      "| 2023-04-27 00:30:04,059 | Testing | INFO | 4 : img_path = /home/rime97410000/ZebraFish_DB/{Dataset}_Cropped/{20230424_Update}_Academia_Sinica_i505/fish_dataset_horiz_cut_1l2_Mix_AP/0.75_STDEV/DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022/test/selected/S/S_fish_130_A_selected_0.tiff\n",
      "| 2023-04-27 00:30:04,060 | Testing | INFO | â€» : total test batches: 20\n",
      "| 2023-04-27 00:30:04,060 | Testing | INFO | load model from `torchvision`, model_name: 'vit_b_16', weights: 'vit_b_16/20230426_13_02_17_{Completed}_{100_epochs_AugOnFly}/best_model.pth'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92245442ea3949d7930e12f1f8bc776a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test :   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-04-27 00:30:06,818 | Testing | INFO | Batch[ 01 / 20 ], # of (ground truth == prediction) in this batch : 108/128\n",
      "| 2023-04-27 00:30:07,498 | Testing | INFO | Batch[ 02 / 20 ], # of (ground truth == prediction) in this batch : 117/128\n",
      "| 2023-04-27 00:30:08,158 | Testing | INFO | Batch[ 03 / 20 ], # of (ground truth == prediction) in this batch : 115/128\n",
      "| 2023-04-27 00:30:08,812 | Testing | INFO | Batch[ 04 / 20 ], # of (ground truth == prediction) in this batch : 116/128\n",
      "| 2023-04-27 00:30:09,479 | Testing | INFO | Batch[ 05 / 20 ], # of (ground truth == prediction) in this batch : 108/128\n",
      "| 2023-04-27 00:30:10,129 | Testing | INFO | Batch[ 06 / 20 ], # of (ground truth == prediction) in this batch : 112/128\n",
      "| 2023-04-27 00:30:10,784 | Testing | INFO | Batch[ 07 / 20 ], # of (ground truth == prediction) in this batch :  91/128\n",
      "| 2023-04-27 00:30:11,455 | Testing | INFO | Batch[ 08 / 20 ], # of (ground truth == prediction) in this batch :  98/128\n",
      "| 2023-04-27 00:30:12,113 | Testing | INFO | Batch[ 09 / 20 ], # of (ground truth == prediction) in this batch :  87/128\n",
      "| 2023-04-27 00:30:12,782 | Testing | INFO | Batch[ 10 / 20 ], # of (ground truth == prediction) in this batch :  84/128\n",
      "| 2023-04-27 00:30:13,448 | Testing | INFO | Batch[ 11 / 20 ], # of (ground truth == prediction) in this batch :  83/128\n",
      "| 2023-04-27 00:30:14,095 | Testing | INFO | Batch[ 12 / 20 ], # of (ground truth == prediction) in this batch :  91/128\n",
      "| 2023-04-27 00:30:14,748 | Testing | INFO | Batch[ 13 / 20 ], # of (ground truth == prediction) in this batch :  97/128\n",
      "| 2023-04-27 00:30:15,409 | Testing | INFO | Batch[ 14 / 20 ], # of (ground truth == prediction) in this batch : 109/128\n",
      "| 2023-04-27 00:30:16,071 | Testing | INFO | Batch[ 15 / 20 ], # of (ground truth == prediction) in this batch : 113/128\n",
      "| 2023-04-27 00:30:16,732 | Testing | INFO | Batch[ 16 / 20 ], # of (ground truth == prediction) in this batch : 115/128\n",
      "| 2023-04-27 00:30:17,396 | Testing | INFO | Batch[ 17 / 20 ], # of (ground truth == prediction) in this batch : 112/128\n",
      "| 2023-04-27 00:30:18,059 | Testing | INFO | Batch[ 18 / 20 ], # of (ground truth == prediction) in this batch : 115/128\n",
      "| 2023-04-27 00:30:18,721 | Testing | INFO | Batch[ 19 / 20 ], # of (ground truth == prediction) in this batch : 108/128\n",
      "| 2023-04-27 00:30:18,869 | Testing | INFO | Batch[ 20 / 20 ], # of (ground truth == prediction) in this batch : 24/28\n"
     ]
    }
   ],
   "source": [
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "testingByImg_logger.info(f\"Using '{device}', device_name = '{device_name}'\")\n",
    "\n",
    "\n",
    "# Get datetime\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "\n",
    "# Set 'np.random.seed'\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_mapper'\n",
    "num2class_list, class2num_dict = get_sortedClassMapper_from_dir(test_selected_dir)\n",
    "testingByImg_logger.info(f\"num2class_list = {num2class_list}, class2num_dict = {class2num_dict}\")\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "test_img_list = glob(os.path.normpath(f\"{test_selected_dir}/*/*.tiff\"))\n",
    "testingByImg_logger.info(f\"total = {len(test_img_list)}\")\n",
    "## debug mode: random select [debug_rand_select] images\n",
    "if debug_mode:\n",
    "    test_img_list = np.random.choice(test_img_list, size=debug_rand_select, replace=False)\n",
    "    testingByImg_logger.info(f\"Debug mode, only select first {len(test_img_list)}\")\n",
    "\n",
    "\n",
    "# Save 'testing_amount'\n",
    "testing_amount = f\"{{ datatest_{len(test_img_list)} }}_{{ test_{len(test_img_list)} }}\"\n",
    "with open(os.path.normpath(f\"{load_dir}/{testing_amount}\"), mode=\"w\") as f_writer: pass\n",
    "\n",
    "\n",
    "# Create 'test_set', 'test_dataloader'\n",
    "testingByImg_logger.info(f\"test_data ({len(test_img_list)})\")\n",
    "[testingByImg_logger.info(f\"{i} : img_path = {test_img_list[i]}\") for i in range(5)]\n",
    "test_set = ImgDataset(test_img_list, class_mapper=class2num_dict, resize=(224, 224), \n",
    "                      use_hsv=use_hsv)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "testingByImg_logger.info(f\"â€» : total test batches: {len(test_dataloader)}\")\n",
    "\n",
    "\n",
    "# Read test ( debug mode only )\n",
    "if debug_mode:\n",
    "    read_test = cv2.imread(test_img_list[-1])\n",
    "    testingByImg_logger.info(f\"Read Test: {test_img_list[-1]}\")\n",
    "    cv2.imshow(\"Read Test\", read_test)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Create model ( ref: https://github.com/pytorch/vision/issues/7397 )\n",
    "testingByImg_logger.info((f\"load model from `torchvision`, \"\n",
    "                          f\"model_name: '{model_name}', weights: '{model_name}/{model_history}/{model_desc}_model.pth'\"))\n",
    "model = getattr(torchvision.models, model_name)\n",
    "model = model(weights=None)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class2num_dict), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "## load 'model_state_dict'\n",
    "model_path = os.path.join(load_dir, f\"{model_desc}_model.pth\")\n",
    "pth_file = torch.load(model_path, map_location=device) # unpack to device directly\n",
    "model.load_state_dict(pth_file[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "# Testing\n",
    "## testing variable\n",
    "test_log = { \"Test\": time_stamp, \"model_desc\": f\"{model_desc}_model.pth\" }\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "## progress bar\n",
    "pbar_n_test = tqdm(total=len(test_dataloader), desc=\"Test \")\n",
    "## start testing\n",
    "## set to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        x_test, y_test, crop_name_batch = data\n",
    "        x_test, y_test = x_test.to(device), y_test.to(device) # move to GPU\n",
    "        preds = model(x_test)\n",
    "        _, pred_test = torch.max(preds, 1)\n",
    "        \n",
    "        ## extend 'pred_list', 'gt_list'\n",
    "        pred_list.extend(pred_test.cpu().numpy().tolist())\n",
    "        gt_list.extend(y_test.cpu().numpy().tolist())\n",
    "        \n",
    "        ## show predict_status of current_batch in CLI\n",
    "        testingByImg_logger.info((f\"Batch[ {(batch+1):0{len(str(len(test_dataloader)))}} / {len(test_dataloader)} ], \"\n",
    "                                  f\"# of (ground truth == prediction) in this batch : \"\n",
    "                                  f\"{(pred_test.cpu() == y_test.cpu()).sum().item():{len(str(len(y_test)))}}/{len(y_test)}\"))\n",
    "        \n",
    "        ## update 'pbar_n_test'\n",
    "        pbar_n_test.update(1)\n",
    "        pbar_n_test.refresh()\n",
    "\n",
    "pbar_n_test.close()\n",
    "## end testing\n",
    "\n",
    "\n",
    "caulculate_metrics(test_log, None,\n",
    "                   gt_list, pred_list, class2num_dict)\n",
    "# print(json.dumps(test_log, indent=4))\n",
    "\n",
    "\n",
    "# Save infomations to a file\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Logs}}_test.log\"), mode=\"w\") as f_writer:\n",
    "\n",
    "    ## change direction of 'sys.stdout'\n",
    "    orig_stdout = sys.stdout # store original 'sys.stdout'\n",
    "    sys.stdout = f_writer\n",
    "\n",
    "    ## write 'test_log'\n",
    "    print(json.dumps(test_log, indent=4), \"\\n\\n\")\n",
    "\n",
    "    ## write 'classification_report'\n",
    "    gt_list_to_name = [ num2class_list[i] for i in gt_list ]\n",
    "    pred_list_to_name = [ num2class_list[i] for i in pred_list ]\n",
    "    cls_report = classification_report(y_true=gt_list_to_name, y_pred=pred_list_to_name)\n",
    "    print(\"Classification Report:\\n\\n\", cls_report, \"\\n\")\n",
    "\n",
    "    ## write 'confusion_matrix'\n",
    "    #   row: Ground truth\n",
    "    #   column: predict\n",
    "    #  *ã€€0ã€€1ã€€2\n",
    "    #  0 [] [] []\n",
    "    #  1 [] [] []\n",
    "    #  2 [] [] []\n",
    "    #\n",
    "    confusion_mat = confusion_matrix_with_class(ground_truth=gt_list_to_name, prediction=pred_list_to_name)\n",
    "\n",
    "    ## recover direct of 'sys.stdout'\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "\n",
    "# Rename 'load_dir'\n",
    "## new_name_format = {time_stamp}_{state}_{target_epochs_with_ImgLoadOptions}_{test_f1}\n",
    "## state = {EarlyStop, Interrupt, Completed, Tested, etc.}\n",
    "model_history_list = re.split(\"{|}\", model_history)\n",
    "new_name = f\"{model_history_list[0]}{{Tested}}_{{{model_history_list[3]}}}_{{{model_desc}}}_{{avg_f1_{test_log['average_f1']}}}\" \n",
    "os.rename(load_dir, os.path.join(load_dir_root, model_name, new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae46fe3be2f97d3a16702042bc6c7abd422dd0bfb5ce5527ad30c3a287e1c756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
