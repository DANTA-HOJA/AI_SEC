{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for `Testing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import traceback\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "import json\n",
    "import toml\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "sys.path.append(\"./../modules/\") # add path to scan customized module\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend, \\\n",
    "                     confusion_matrix_with_class, get_sortedClassMapper_from_dir\n",
    "from plt_show import plot_in_rgb # server can't use `cv.imshow()`\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredByImg_logger = init_logger(r\"Predict By Image\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `vit_b_16_PredByImg.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../Config/vit_b_16_PredByImg.toml\", mode=\"r\") as f_reader:\n",
    "    config = toml.load(f_reader)\n",
    "    \n",
    "batch_size        = config[\"test_opts\"][\"batch_size\"]\n",
    "debug_mode        = config[\"test_opts\"][\"debug_mode\"][\"enable\"]\n",
    "debug_rand_select = config[\"test_opts\"][\"debug_mode\"][\"rand_select\"]\n",
    "cuda_idx          = config[\"test_opts\"][\"cuda\"][\"index\"]\n",
    "\n",
    "load_dir_root = config[\"model\"][\"history_root\"]\n",
    "model_history = config[\"model\"][\"history\"]\n",
    "model_desc    = config[\"model\"][\"desc\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `train_config.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join(load_dir_root, model_history)\n",
    "train_config_path = os.path.join(load_dir, r\"train_config.toml\")\n",
    "\n",
    "with open(train_config_path, mode=\"r\") as f_reader:\n",
    "    train_config = toml.load(f_reader)\n",
    "\n",
    "dataset_root             = os.path.normpath(train_config[\"dataset\"][\"root\"])\n",
    "dataset_name             = train_config[\"dataset\"][\"name\"]\n",
    "dataset_palmskin_desc    = train_config[\"dataset\"][\"palmskin_desc\"]\n",
    "dataset_gen_method       = train_config[\"dataset\"][\"gen_method\"]\n",
    "dataset_result_alias     = train_config[\"dataset\"][\"result_alias\"]\n",
    "dataset_classif_strategy = train_config[\"dataset\"][\"classif_strategy\"]\n",
    "dataset_param_name       = train_config[\"dataset\"][\"param_name\"]\n",
    "\n",
    "model_name = train_config[\"model\"][\"model_name\"]\n",
    "\n",
    "rand_seed = train_config[\"train_opts\"][\"random_seed\"]\n",
    "use_hsv   = train_config[\"train_opts\"][\"data\"][\"use_hsv\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `dataset_config.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(dataset_root, dataset_name, dataset_palmskin_desc, dataset_gen_method, \n",
    "                                    dataset_result_alias, dataset_classif_strategy, dataset_param_name)\n",
    "dataset_config_path = os.path.join(dataset_dir, r\"dataset_config.toml\")\n",
    "\n",
    "with open(dataset_config_path, mode=\"r\") as f_reader:\n",
    "    dataset_config = toml.load(f_reader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate `path_vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected_dir = os.path.join(dataset_dir, \"test\", \"selected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "PredByImg_logger.info(f\"Using '{device}', device_name = '{device_name}'\")\n",
    "\n",
    "\n",
    "# Get datetime\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "\n",
    "# Set 'np.random.seed'\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_mapper'\n",
    "num2class_list, class2num_dict = get_sortedClassMapper_from_dir(test_selected_dir)\n",
    "PredByImg_logger.info(f\"num2class_list = {num2class_list}, class2num_dict = {class2num_dict}\")\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "test_img_list = glob(os.path.normpath(f\"{test_selected_dir}/*/*.tiff\"))\n",
    "PredByImg_logger.info(f\"total = {len(test_img_list)}\")\n",
    "## debug mode: random select [debug_rand_select] images\n",
    "if debug_mode:\n",
    "    test_img_list = np.random.choice(test_img_list, size=debug_rand_select, replace=False)\n",
    "    PredByImg_logger.info(f\"Debug mode, only select first {len(test_img_list)}\")\n",
    "\n",
    "\n",
    "# Save 'testing_amount'\n",
    "testing_amount = f\"{{ datatest_{len(test_img_list)} }}_{{ test_{len(test_img_list)} }}\"\n",
    "with open(os.path.normpath(f\"{load_dir}/{testing_amount}\"), mode=\"w\") as f_writer: pass\n",
    "\n",
    "\n",
    "# Create 'test_set', 'test_dataloader'\n",
    "PredByImg_logger.info(f\"test_data ({len(test_img_list)})\")\n",
    "[PredByImg_logger.info(f\"{i} : img_path = {test_img_list[i]}\") for i in range(5)]\n",
    "test_set = ImgDataset(test_img_list, class_mapper=class2num_dict, resize=(224, 224), \n",
    "                      use_hsv=use_hsv)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "PredByImg_logger.info(f\"â€» : total test batches: {len(test_dataloader)}\")\n",
    "\n",
    "\n",
    "# Read test ( debug mode only )\n",
    "if debug_mode:\n",
    "    PredByImg_logger.info(f\"Read Test: {test_img_list[-1]}\")\n",
    "    plot_in_rgb(test_img_list[-1], (512, 512))\n",
    "\n",
    "\n",
    "# Create model ( ref: https://github.com/pytorch/vision/issues/7397 )\n",
    "PredByImg_logger.info((f\"load model from `torchvision`, \"\n",
    "                          f\"model_name: '{model_name}', weights: '{model_name}/{model_history}/{model_desc}_model.pth'\"))\n",
    "model = getattr(torchvision.models, model_name)\n",
    "model = model(weights=None)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class2num_dict), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "## load 'model_state_dict'\n",
    "model_path = os.path.join(load_dir, f\"{model_desc}_model.pth\")\n",
    "pth_file = torch.load(model_path, map_location=device) # unpack to device directly\n",
    "model.load_state_dict(pth_file[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "# Testing\n",
    "## testing variable\n",
    "test_f1_log = {}\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "## progress bar\n",
    "pbar_n_test = tqdm(total=len(test_dataloader), desc=\"Test \")\n",
    "## start testing\n",
    "## set to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        x_test, y_test, crop_name_batch = data\n",
    "        x_test, y_test = x_test.to(device), y_test.to(device) # move to GPU\n",
    "        preds = model(x_test)\n",
    "        pred_prob = torch.nn.functional.softmax(preds, dim=1)\n",
    "        _, pred_test = torch.max(pred_prob, 1)\n",
    "        \n",
    "        ## extend 'pred_list', 'gt_list'\n",
    "        pred_list.extend(pred_test.cpu().numpy().tolist())\n",
    "        gt_list.extend(y_test.cpu().numpy().tolist())\n",
    "        \n",
    "        ## show predict_status of current_batch in CLI\n",
    "        PredByImg_logger.info((f\"Batch[ {(batch+1):0{len(str(len(test_dataloader)))}} / {len(test_dataloader)} ], \"\n",
    "                               f\"# of (ground truth == prediction) in this batch : \"\n",
    "                               f\"{(pred_test.cpu() == y_test.cpu()).sum().item():{len(str(len(y_test)))}}/{len(y_test)}\"))\n",
    "        \n",
    "        ## update 'pbar_n_test'\n",
    "        pbar_n_test.update(1)\n",
    "        pbar_n_test.refresh()\n",
    "\n",
    "pbar_n_test.close()\n",
    "## end testing\n",
    "\n",
    "\n",
    "gt_list_to_name = [ num2class_list[i] for i in gt_list ]\n",
    "pred_list_to_name = [ num2class_list[i] for i in pred_list ]\n",
    "\n",
    "caulculate_metrics(test_f1_log, None,\n",
    "                   gt_list_to_name, pred_list_to_name, class2num_dict)\n",
    "# print(json.dumps(test_f1_log, indent=4))\n",
    "\n",
    "\n",
    "# Save `test_f1_log`\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Logs}}_PredByImg_maweavg_f1_{test_f1_log['maweavg_f1']}.toml\"), mode=\"w\") as f_writer:\n",
    "    f_writer.write(toml.dumps(test_f1_log))\n",
    "\n",
    "# Save infomations to a file\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Report}}_PredByImg.log\"), mode=\"w\") as f_writer:\n",
    "\n",
    "    ## change direction of 'sys.stdout'\n",
    "    orig_stdout = sys.stdout # store original 'sys.stdout'\n",
    "    sys.stdout = f_writer\n",
    "\n",
    "    ## write `config`\n",
    "    config_model = deepcopy(config[\"model\"])\n",
    "    config_model.pop(\"history_root\")\n",
    "    print(\"[ model ]\"); print(toml.dumps(config_model))\n",
    "    \n",
    "    train_config_dataset = deepcopy(train_config[\"dataset\"])\n",
    "    train_config_dataset.pop(\"root\")\n",
    "    print(\"[ dataset ]\"); print(toml.dumps(train_config_dataset))\n",
    "    \n",
    "    dataset_config_brightfield = deepcopy(dataset_config[\"data\"][\"brightfield\"])\n",
    "    print(\"[ data.brightfield ]\"); print(toml.dumps(dataset_config_brightfield))\n",
    "    \n",
    "    dataset_config_stacked_palmskin = deepcopy(dataset_config[\"data\"][\"stacked_palmskin\"])\n",
    "    print(\"[ data.stacked_palmskin ]\"); print(toml.dumps(dataset_config_stacked_palmskin))\n",
    "    \n",
    "    print(f\"â€» For more detail info please refer to its 'train_config' file...\\n\\n\") # newline\n",
    "\n",
    "\n",
    "    ## write 'classification_report'\n",
    "    cls_report = classification_report(y_true=gt_list_to_name, y_pred=pred_list_to_name, digits=5)\n",
    "    print(\"Classification Report:\\n\"); print(f\"{cls_report}\\n\")\n",
    "\n",
    "    ## write 'confusion_matrix'\n",
    "    #   row: Ground truth\n",
    "    #   column: predict\n",
    "    #  *ã€€0ã€€1ã€€2\n",
    "    #  0 [] [] []\n",
    "    #  1 [] [] []\n",
    "    #  2 [] [] []\n",
    "    #\n",
    "    confusion_mat = confusion_matrix_with_class(ground_truth=gt_list_to_name, prediction=pred_list_to_name)\n",
    "\n",
    "    ## recover direct of 'sys.stdout'\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "\n",
    "# Rename 'load_dir'\n",
    "## new_name_format = {time_stamp}_{state}_{target_epochs_with_ImgLoadOptions}_{test_f1}\n",
    "## state = {EarlyStop, Interrupt, Completed, Tested, etc.}\n",
    "model_history_list = re.split(\"{|}\", model_history)\n",
    "new_name = f\"{model_history_list[0]}{{Tested_PredByImg}}_{{{model_history_list[3]}}}_{{{model_desc}}}_{{maweavg_f1_{test_f1_log['maweavg_f1']}}}\" \n",
    "os.rename(load_dir, os.path.join(load_dir_root, new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae46fe3be2f97d3a16702042bc6c7abd422dd0bfb5ce5527ad30c3a287e1c756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
