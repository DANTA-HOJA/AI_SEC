{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for ```Testing```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import traceback\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\confocal_microscope\\Desktop\\ZebraFish_AP_POS\\modules\") # add path to scan customized module\n",
    "from logger import init_logger\n",
    "from fileop import create_new_dir\n",
    "from dl_utils import set_gpu, ImgDataset, caulculate_metrics, save_model, plot_training_trend, \\\n",
    "                     confusion_matrix_with_class, get_sortedClassMapper_from_dir\n",
    "\n",
    "# print(\"=\"*100, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_logger = init_logger(r\"Testing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_dataset_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\"\n",
    "load_dir_root = r\"C:\\Users\\confocal_microscope\\Desktop\\{Test}_Model_history\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-03-30 13:24:15,838 | Testing | INFO | Using 'cuda', device_name = 'NVIDIA GeForce RTX 2080 Ti'\n"
     ]
    }
   ],
   "source": [
    "dataset_name = r\"{20230305_NEW_STRUCT}_Academia_Sinica_i409\"\n",
    "dataset_gen_method = \"fish_dataset_horiz_cut_1l2_Mix_AP\"\n",
    "dataset_param_name = \"DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\"\n",
    "cuda_idx = 1\n",
    "label_in_filename = 0\n",
    "batch_size = 32\n",
    "model_name = \"vit_b_16\"\n",
    "model_history = r\"20230330_11_51_20_{EarlyStop}_{45_epochs_AugOnFly}\"\n",
    "model_desc = \"best\" # best / final\n",
    "use_hsv = False # using 'HSV' when getting images from the 'ImgDataset'\n",
    "\n",
    "debug_mode = False\n",
    "rand_seed = 2022 # only for debug_mode\n",
    "\n",
    "# Create path var\n",
    "load_dir = os.path.join(load_dir_root, model_name, model_history)\n",
    "test_selected_dir = os.path.join(ap_dataset_root, dataset_name, dataset_gen_method, dataset_param_name, \"test\", \"selected\")\n",
    "\n",
    "# Set GPU\n",
    "device, device_name = set_gpu(cuda_idx)\n",
    "testing_logger.info(f\"Using '{device}', device_name = '{device_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-03-30 13:24:15,938 | Testing | INFO | {'L': 0, 'M': 1, 'S': 2}\n",
      "| 2023-03-30 13:24:15,951 | Testing | INFO | total = 1990\n",
      "| 2023-03-30 13:24:15,951 | Testing | INFO | test_data (1990)\n",
      "| 2023-03-30 13:24:15,952 | Testing | INFO | 0：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_100_A_selected_0.tiff\n",
      "| 2023-03-30 13:24:15,952 | Testing | INFO | 1：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_100_A_selected_1.tiff\n",
      "| 2023-03-30 13:24:15,953 | Testing | INFO | 2：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_100_A_selected_2.tiff\n",
      "| 2023-03-30 13:24:15,953 | Testing | INFO | 3：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_100_A_selected_3.tiff\n",
      "| 2023-03-30 13:24:15,954 | Testing | INFO | 4：img_path = C:\\Users\\confocal_microscope\\Desktop\\{Test}_DataSet\\{20230305_NEW_STRUCT}_Academia_Sinica_i409\\fish_dataset_horiz_cut_1l2_Mix_AP\\DS_SURF3C_CRPS512_SF14_INT20_DRP100_RS2022\\test\\selected\\L\\L_fish_100_A_selected_4.tiff\n",
      "| 2023-03-30 13:24:15,955 | Testing | INFO | total test batches: 63\n",
      "| 2023-03-30 13:24:15,955 | Testing | INFO | load model using 'torch.hub.load()', model_name: 'vit_b_16', weights: 'vit_b_16/20230330_11_51_20_{EarlyStop}_{45_epochs_AugOnFly}/final_model.pth'\n",
      "Using cache found in C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\n",
      "C:\\Users\\confocal_microscope/.cache\\torch\\hub\\pytorch_vision_main\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3396a310b83e4ddfa6e2f6a463d612a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test :   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 2023-03-30 13:24:21,226 | Testing | INFO | Batch[ 01 / 63 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-03-30 13:24:21,593 | Testing | INFO | Batch[ 02 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:21,920 | Testing | INFO | Batch[ 03 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:22,256 | Testing | INFO | Batch[ 04 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:22,587 | Testing | INFO | Batch[ 05 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:22,913 | Testing | INFO | Batch[ 06 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:23,238 | Testing | INFO | Batch[ 07 / 63 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-03-30 13:24:23,561 | Testing | INFO | Batch[ 08 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:23,891 | Testing | INFO | Batch[ 09 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:24,219 | Testing | INFO | Batch[ 10 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:24,547 | Testing | INFO | Batch[ 11 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:24,867 | Testing | INFO | Batch[ 12 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:25,197 | Testing | INFO | Batch[ 13 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:25,520 | Testing | INFO | Batch[ 14 / 63 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-03-30 13:24:25,861 | Testing | INFO | Batch[ 15 / 63 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-03-30 13:24:26,190 | Testing | INFO | Batch[ 16 / 63 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-03-30 13:24:26,527 | Testing | INFO | Batch[ 17 / 63 ], # of (ground truth == prediction) in_this_batch： 22/32\n",
      "| 2023-03-30 13:24:26,849 | Testing | INFO | Batch[ 18 / 63 ], # of (ground truth == prediction) in_this_batch： 12/32\n",
      "| 2023-03-30 13:24:27,172 | Testing | INFO | Batch[ 19 / 63 ], # of (ground truth == prediction) in_this_batch：  4/32\n",
      "| 2023-03-30 13:24:27,497 | Testing | INFO | Batch[ 20 / 63 ], # of (ground truth == prediction) in_this_batch： 24/32\n",
      "| 2023-03-30 13:24:27,822 | Testing | INFO | Batch[ 21 / 63 ], # of (ground truth == prediction) in_this_batch： 22/32\n",
      "| 2023-03-30 13:24:28,156 | Testing | INFO | Batch[ 22 / 63 ], # of (ground truth == prediction) in_this_batch： 27/32\n",
      "| 2023-03-30 13:24:28,488 | Testing | INFO | Batch[ 23 / 63 ], # of (ground truth == prediction) in_this_batch：  7/32\n",
      "| 2023-03-30 13:24:28,816 | Testing | INFO | Batch[ 24 / 63 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-03-30 13:24:29,138 | Testing | INFO | Batch[ 25 / 63 ], # of (ground truth == prediction) in_this_batch：  5/32\n",
      "| 2023-03-30 13:24:29,452 | Testing | INFO | Batch[ 26 / 63 ], # of (ground truth == prediction) in_this_batch： 21/32\n",
      "| 2023-03-30 13:24:29,782 | Testing | INFO | Batch[ 27 / 63 ], # of (ground truth == prediction) in_this_batch： 15/32\n",
      "| 2023-03-30 13:24:30,112 | Testing | INFO | Batch[ 28 / 63 ], # of (ground truth == prediction) in_this_batch： 11/32\n",
      "| 2023-03-30 13:24:30,436 | Testing | INFO | Batch[ 29 / 63 ], # of (ground truth == prediction) in_this_batch： 12/32\n",
      "| 2023-03-30 13:24:30,771 | Testing | INFO | Batch[ 30 / 63 ], # of (ground truth == prediction) in_this_batch： 27/32\n",
      "| 2023-03-30 13:24:31,107 | Testing | INFO | Batch[ 31 / 63 ], # of (ground truth == prediction) in_this_batch： 22/32\n",
      "| 2023-03-30 13:24:31,449 | Testing | INFO | Batch[ 32 / 63 ], # of (ground truth == prediction) in_this_batch： 21/32\n",
      "| 2023-03-30 13:24:31,787 | Testing | INFO | Batch[ 33 / 63 ], # of (ground truth == prediction) in_this_batch： 18/32\n",
      "| 2023-03-30 13:24:32,129 | Testing | INFO | Batch[ 34 / 63 ], # of (ground truth == prediction) in_this_batch：  9/32\n",
      "| 2023-03-30 13:24:32,470 | Testing | INFO | Batch[ 35 / 63 ], # of (ground truth == prediction) in_this_batch： 11/32\n",
      "| 2023-03-30 13:24:32,800 | Testing | INFO | Batch[ 36 / 63 ], # of (ground truth == prediction) in_this_batch： 23/32\n",
      "| 2023-03-30 13:24:33,139 | Testing | INFO | Batch[ 37 / 63 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-03-30 13:24:33,472 | Testing | INFO | Batch[ 38 / 63 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-03-30 13:24:33,807 | Testing | INFO | Batch[ 39 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:34,135 | Testing | INFO | Batch[ 40 / 63 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-03-30 13:24:34,457 | Testing | INFO | Batch[ 41 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:34,779 | Testing | INFO | Batch[ 42 / 63 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-03-30 13:24:35,102 | Testing | INFO | Batch[ 43 / 63 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-03-30 13:24:35,443 | Testing | INFO | Batch[ 44 / 63 ], # of (ground truth == prediction) in_this_batch： 20/32\n",
      "| 2023-03-30 13:24:35,770 | Testing | INFO | Batch[ 45 / 63 ], # of (ground truth == prediction) in_this_batch： 25/32\n",
      "| 2023-03-30 13:24:36,095 | Testing | INFO | Batch[ 46 / 63 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-03-30 13:24:36,414 | Testing | INFO | Batch[ 47 / 63 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-03-30 13:24:36,733 | Testing | INFO | Batch[ 48 / 63 ], # of (ground truth == prediction) in_this_batch： 31/32\n",
      "| 2023-03-30 13:24:37,060 | Testing | INFO | Batch[ 49 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:37,396 | Testing | INFO | Batch[ 50 / 63 ], # of (ground truth == prediction) in_this_batch： 23/32\n",
      "| 2023-03-30 13:24:37,729 | Testing | INFO | Batch[ 51 / 63 ], # of (ground truth == prediction) in_this_batch： 28/32\n",
      "| 2023-03-30 13:24:38,059 | Testing | INFO | Batch[ 52 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:38,387 | Testing | INFO | Batch[ 53 / 63 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-03-30 13:24:38,719 | Testing | INFO | Batch[ 54 / 63 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-03-30 13:24:39,048 | Testing | INFO | Batch[ 55 / 63 ], # of (ground truth == prediction) in_this_batch： 30/32\n",
      "| 2023-03-30 13:24:39,376 | Testing | INFO | Batch[ 56 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:39,714 | Testing | INFO | Batch[ 57 / 63 ], # of (ground truth == prediction) in_this_batch： 29/32\n",
      "| 2023-03-30 13:24:40,055 | Testing | INFO | Batch[ 58 / 63 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-03-30 13:24:40,395 | Testing | INFO | Batch[ 59 / 63 ], # of (ground truth == prediction) in_this_batch： 23/32\n",
      "| 2023-03-30 13:24:40,729 | Testing | INFO | Batch[ 60 / 63 ], # of (ground truth == prediction) in_this_batch： 26/32\n",
      "| 2023-03-30 13:24:41,059 | Testing | INFO | Batch[ 61 / 63 ], # of (ground truth == prediction) in_this_batch： 32/32\n",
      "| 2023-03-30 13:24:41,394 | Testing | INFO | Batch[ 62 / 63 ], # of (ground truth == prediction) in_this_batch： 24/32\n",
      "| 2023-03-30 13:24:41,463 | Testing | INFO | Batch[ 63 / 63 ], # of (ground truth == prediction) in_this_batch： 1/6\n"
     ]
    }
   ],
   "source": [
    "# Get datetime\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "\n",
    "\n",
    "# Set 'np.random.seed'\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "\n",
    "# Scan classes to create 'class_mapper'\n",
    "num2class_list, class2num_dict = get_sortedClassMapper_from_dir(test_selected_dir)\n",
    "testing_logger.info(class2num_dict)\n",
    "\n",
    "\n",
    "# Scan tiff\n",
    "test_img_list = glob(os.path.normpath(f\"{test_selected_dir}/*/*.tiff\"))\n",
    "testing_logger.info(f\"total = {len(test_img_list)}\")\n",
    "## debug mode: only select first 200\n",
    "if debug_mode:\n",
    "    test_img_list = np.random.choice(test_img_list, size=200, replace=False)\n",
    "    testing_logger.info(f\"Debug mode, only select first {len(test_img_list)}\")\n",
    "\n",
    "\n",
    "# Split train, test dataset\n",
    "testing_logger.info(f\"test_data ({len(test_img_list)})\")\n",
    "[testing_logger.info(f\"{i}：img_path = {test_img_list[i]}\") for i in range(5)]\n",
    "## debug mode: read test\n",
    "if debug_mode:\n",
    "    reat_test = cv2.imread(test_img_list[-1])\n",
    "    testing_logger.info(f\"Read Test: {test_img_list[-1]}\")\n",
    "    cv2.imshow(\"Read Test\", reat_test)\n",
    "    cv2.waitKey(0)\n",
    "## save 'training_amount'\n",
    "training_amount = f\"{{ datatest_{len(test_img_list)} }}_{{ test_{len(test_img_list)} }}\"\n",
    "with open(os.path.normpath(f\"{load_dir}/{training_amount}\"), mode=\"w\") as f_writer: pass\n",
    "\n",
    "\n",
    "# Create dataSets\n",
    "test_set = ImgDataset(test_img_list, class_mapper=class2num_dict, label_in_filename=label_in_filename, use_hsv=use_hsv)\n",
    "\n",
    "\n",
    "# Initial dataLoader\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "testing_logger.info(f\"total test batches: {len(test_dataloader)}\")\n",
    "\n",
    "\n",
    "# Create model\n",
    "testing_logger.info((f\"load model using 'torch.hub.load()', \"\n",
    "                 f\"model_name: '{model_name}', weights: '{model_name}/{model_history}/{model_desc}_model.pth'\"))\n",
    "model = torch.hub.load('pytorch/vision', model_name, weights=None)\n",
    "## modify model structure\n",
    "model.heads.head = nn.Linear(in_features=768, out_features=len(class2num_dict), bias=True)\n",
    "model.to(device)\n",
    "# print(model)\n",
    "## load model_state_dict\n",
    "model_path = os.path.join(load_dir, f\"{model_desc}_model.pth\")\n",
    "pth_file = torch.load(model_path, map_location=device) # unpack to device directly\n",
    "model.load_state_dict(pth_file[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "# Testing\n",
    "## testing variable\n",
    "test_log = { \"Test\": time_stamp, \"model_desc\": f\"{model_desc}_model.pth\" }\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "## progress bar\n",
    "pbar_n_test = tqdm(total=len(test_dataloader), desc=\"Test \")\n",
    "## start testing\n",
    "## set to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        x_test, y_test = data\n",
    "        x_test, y_test = x_test.to(device), y_test.to(device) # move to GPU\n",
    "        preds = model(x_test)\n",
    "        _, pred_test = torch.max(preds, 1)\n",
    "        \n",
    "        ## extend 'pred_list', 'gt_list'\n",
    "        pred_list.extend(pred_test.cpu().numpy().tolist())\n",
    "        gt_list.extend(y_test.cpu().numpy().tolist())\n",
    "        \n",
    "        ## show predict_status of current_batch in CLI\n",
    "        testing_logger.info((f\"Batch[ {(batch+1):0{len(str(len(test_dataloader)))}} / {len(test_dataloader)} ], \"\n",
    "                             f\"# of (ground truth == prediction) in_this_batch： \"\n",
    "                             f\"{(pred_test.cpu() == y_test.cpu()).sum().item():{len(str(len(y_test)))}}/{len(y_test)}\"))\n",
    "        \n",
    "        ## update 'pbar_n_test'\n",
    "        pbar_n_test.update(1)\n",
    "        pbar_n_test.refresh()\n",
    "\n",
    "caulculate_metrics(test_log, None,\n",
    "                   gt_list, pred_list, class2num_dict)\n",
    "# print(json.dumps(test_log, indent=4))\n",
    "pbar_n_test.close()\n",
    "## end testing\n",
    "\n",
    "\n",
    "# Save infomations to a file\n",
    "with open(os.path.normpath(f\"{load_dir}/{{Logs}}_test.log\"), mode=\"w\") as f_writer:\n",
    "\n",
    "    ## change direction of 'sys.stdout'\n",
    "    orig_stdout = sys.stdout # store original 'sys.stdout'\n",
    "    sys.stdout = f_writer\n",
    "\n",
    "    ## write 'test_log'\n",
    "    print(json.dumps(test_log, indent=4), \"\\n\\n\")\n",
    "\n",
    "    ## write 'classification_report'\n",
    "    gt_list_to_name = [ num2class_list[i] for i in gt_list ]\n",
    "    pred_list_to_name = [ num2class_list[i] for i in pred_list ]\n",
    "    cls_report = classification_report(y_true=gt_list_to_name, y_pred=pred_list_to_name)\n",
    "    print(\"Classification Report:\\n\\n\", cls_report, \"\\n\")\n",
    "\n",
    "    ## write 'confusion_matrix'\n",
    "    #   row: Ground truth\n",
    "    #   column: predict\n",
    "    #  *　0　1　2\n",
    "    #  0 [] [] []\n",
    "    #  1 [] [] []\n",
    "    #  2 [] [] []\n",
    "    #\n",
    "    confusion_mat = confusion_matrix_with_class(ground_truth=gt_list_to_name, prediction=pred_list_to_name)\n",
    "\n",
    "    ## recover direct of 'sys.stdout'\n",
    "    sys.stdout = orig_stdout\n",
    "\n",
    "\n",
    "# Rename 'load_dir'\n",
    "## new_name_format = {time_stamp}_{state}_{target_epochs_with_ImgLoadOptions}_{test_f1}\n",
    "## state = {EarlyStop, Interrupt, Completed, Tested, etc.}\n",
    "model_history_list = re.split(\"{|}\", model_history)\n",
    "new_name = f\"{model_history_list[0]}{{Tested}}_{{{model_history_list[3]}}}_{{{model_desc}}}_{{avg_f1_{test_log['average_f1']}}}\" \n",
    "os.rename(load_dir, os.path.join(load_dir_root, model_name, new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
