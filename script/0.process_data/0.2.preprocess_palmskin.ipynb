{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Customized modules and Create ImageJ Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union, TextIO\n",
    "from datetime import datetime\n",
    "import toml\n",
    "import tomlkit\n",
    "\n",
    "import logging\n",
    "from skimage.io import imread, imshow, imsave\n",
    "\n",
    "abs_module_path = Path(\"./../../\").resolve()\n",
    "if (abs_module_path.exists()) and (str(abs_module_path) not in sys.path):\n",
    "    sys.path.append(str(abs_module_path)) # add path to scan customized module\n",
    "\n",
    "from modules.misc.logger import init_logger\n",
    "from modules.misc.utils import create_new_dir, get_repo_root, load_config\n",
    "from modules.data.lif import LIFNameChecker, scan_lifs_under_dir\n",
    "from modules.data.composite_ij import dump_info, median_R1_and_mean3D_R2, save_tif_with_SN, \\\n",
    "                                      group_show, group_hide, crop_threshold_rect, create_rect, \\\n",
    "                                      direct_max_zproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = init_logger(r\"Palmskin Preprocess\")\n",
    "lif_name_checker = LIFNameChecker()\n",
    "\n",
    "repo_root = get_repo_root()\n",
    "print(f\"Repository: '{repo_root}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_loc = os.getcwd()\n",
    "orig_stdout = sys.stdout # store original 'sys.stdout'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `db_path_plan.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpp_config = load_config(\"db_path_plan.toml\")\n",
    "\n",
    "db_root      = Path(dbpp_config[\"root\"])\n",
    "fiji_app_dir = Path(dbpp_config[\"fiji_app\"])\n",
    "data_nasdl   = dbpp_config[\"data_nasdl\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `(Preprocess)_palmskin.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../../Config/(Preprocess)_palmskin.toml\", mode=\"r\") as f_reader:\n",
    "    config = toml.load(f_reader)\n",
    "\n",
    "preprocessed_desc = config[\"data_preprocessed\"][\"desc\"]\n",
    "preprocessed_reminder = config[\"data_preprocessed\"][\"reminder\"]\n",
    "\n",
    "nas_dl_name       = config[\"data_nas_dl\"][\"name\"]\n",
    "nas_dl_source_dirs = config[\"data_nas_dl\"][\"source_dirs\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate `path_vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_MODE = False\n",
    "\n",
    "# Check `{desc}_Academia_Sinica_i[num]`\n",
    "data_preprocessed_root = db_root.joinpath(dbpp_config[\"data_preprocessed\"])\n",
    "target_dir_list = list(data_preprocessed_root.glob(f\"*{preprocessed_desc}*\"))\n",
    "assert len(target_dir_list) <= 1, (f\"[data_preprocessed.desc] in `(Preprocess)_palmskin.toml` is not unique, \"\n",
    "                                   f\"find {len(target_dir_list)} possible directories, {target_dir_list}\")\n",
    "if target_dir_list:\n",
    "    data_preprocessed_dir = target_dir_list[0]\n",
    "    UPDATE_MODE = True\n",
    "else:\n",
    "    data_preprocessed_dir = data_preprocessed_root.joinpath(f\"{{{preprocessed_desc}}}_Academia_Sinica_iTBA\")\n",
    "\n",
    "\n",
    "# Check `{reminder}_PalmSkin_preprocess`\n",
    "target_dir_list = list(data_preprocessed_dir.glob(f\"*PalmSkin_preprocess*\"))\n",
    "assert len(target_dir_list) <= 1, (f\"Too many directories are found, only one `PalmSkin_preprocess` is accepted. \"\n",
    "                                   f\"Directories: {target_dir_list}\")\n",
    "if target_dir_list:\n",
    "    palmskin_preprocess_dir = target_dir_list[0]\n",
    "else:\n",
    "    palmskin_preprocess_dir = data_preprocessed_dir.joinpath(f\"{{{preprocessed_reminder}}}_PalmSkin_preprocess\")\n",
    "\n",
    "\n",
    "create_new_dir(palmskin_preprocess_dir, display_in_CLI=False)\n",
    "recyclebin_dir = palmskin_preprocess_dir.joinpath(\"!~delete\")\n",
    "create_new_dir(recyclebin_dir, display_in_CLI=False)\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "raw_lif_dir = db_root.joinpath(dbpp_config[\"data_nasdl\"], nas_dl_name, \"palmskin_RGB_RAW\")\n",
    "assert raw_lif_dir.exists(), f\"Can't find '{raw_lif_dir}'\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize PyImageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module\n",
    "import jpype\n",
    "# Enable Java imports\n",
    "import jpype.imports\n",
    "# Pull in types\n",
    "from jpype.types import *\n",
    "\n",
    "import scyjava as sj # scyjava : Supercharged Java access from Python, see https://github.com/scijava/scyjava\n",
    "import imagej\n",
    "\n",
    "# Configurations\n",
    "# NOTE: The ImageJ2 gateway is initialized through a Java Virtual Machine (JVM). If you want to configure the JVM, it must be done before initializing an ImageJ2 gateway.\n",
    "# sj.config.add_option('-Xmx10g') # adjust memory available to Java\n",
    "sj.config.endpoints.append('ome:formats-gpl:6.11.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fiji_Local = str(fiji_app_dir)\n",
    "\n",
    "# ij = imagej.init(Fiji_Local) # Same as \"ij = imagej.init(Fiji_Local, mode='headless')\", PyImageJ’s default mode is headless\n",
    "# ij = imagej.init(Fiji_Local, mode='gui') # GUI mode (會卡在這一行 -> blocking), for more explainations : https://pyimagej.readthedocs.io/en/latest/Initialization.html#gui-mode\n",
    "ij = imagej.init(Fiji_Local, mode='interactive') # Interactive mode (可以繼續向下執行 -> non-blocking), for more explainations : https://pyimagej.readthedocs.io/en/latest/Initialization.html#interactive-mode\n",
    "ij.ui().showUI() # display the Fiji GUI\n",
    "\n",
    "print(ij.getApp().getInfo(True)) # ImageJ2 2.9.0/1.54b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bio-Format Reader\n",
    "loci = jpype.JPackage(\"loci\")\n",
    "loci.common.DebugTools.setRootLevel(\"ERROR\")\n",
    "Reader = loci.formats.ImageReader()\n",
    "\n",
    "# [IMPORTANT] some ImageJ plugins need to be new before use\n",
    "from ij.plugin.frame import RoiManager\n",
    "from ij.plugin import ImageCalculator\n",
    "from ij.plugin import ChannelSplitter\n",
    "from ij.plugin import ZProjector\n",
    "from ij.plugin import RGBStackMerge\n",
    "from ij.plugin import RGBStackConverter\n",
    "\n",
    "rm = RoiManager()\n",
    "imageCalculator = ImageCalculator()\n",
    "channelSplitter = ChannelSplitter()\n",
    "zProjector = ZProjector()\n",
    "rgbStackMerge = RGBStackMerge()\n",
    "rgbStackConverter = RGBStackConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(orig_loc)\n",
    "sys.stdout = orig_stdout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test : RGB image name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_string = r\"Series001_fish_1_palmskin_8dpf_A\"\n",
    "test_string = r\"Series001_fish_165_A_RG\"\n",
    "\n",
    "\n",
    "# Check format of 'image_name'\n",
    "detect_old_new_list = re.findall(\"[RGB]\", test_string)\n",
    "# print(detect_old_new_list)\n",
    "image_name_list = re.split(\" |_|-\", test_string)\n",
    "if len(detect_old_new_list) > 0: failed_cnt, check_dict = check_image_name(image_name_list, \"new_rgb\", debug_mode=True)\n",
    "else: failed_cnt, check_dict = check_image_name(image_name_list, \"old_rgb\", debug_mode=True)\n",
    "\n",
    "\n",
    "# Consociate image_name\n",
    "if (check_dict[\"    format_and_type     \"] == \"old_rgb\") and (failed_cnt == 0): # name check passed, generate new name\n",
    "    image_name_list.pop(3) # palmskin (old name only)\n",
    "    image_name_list.pop(3) # [num]dpf (old name only)\n",
    "    image_name_list.append(\"RGB\")\n",
    "image_name = \"_\".join(image_name_list)\n",
    "\n",
    "\n",
    "# logger.info() --> ERRORs when checking 'image_name'\n",
    "if failed_cnt == -1 : logger.info(check_dict[\"  len(image_name_list)  \"])\n",
    "if failed_cnt > 0 : logger.info(check_dict[\"     failed warning     \"])\n",
    "\n",
    "# log_writer.write() --> ERRORs when checking 'image_name'\n",
    "if failed_cnt == -1 : print(\"| {} \\n\".format(check_dict[\"  len(image_name_list)  \"].strip()))\n",
    "if failed_cnt > 0: print(\"| {} \\n\".format(check_dict[\"     failed warning     \"].strip()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single_palmskin_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_palmskin_preprocess(lif_path:str, total_lif_file:int, out_dir_root:str, logger:logging.Logger, log_writer:TextIO, \n",
    "                               Kuwahara_sampleing:int, bf_zproj_type:str, bf_treshold_value:int, relative_mask:str):\n",
    "    \n",
    "    \n",
    "    logger.info(f'LIF_FILE : {lif_path}')\n",
    "    \n",
    "    Reader.setId(lif_path)\n",
    "    seriesCount = Reader.getSeriesCount()\n",
    "    # logger.info(f'seriesCount : {seriesCount}')\n",
    "    \n",
    "    \n",
    "    for idx in range(seriesCount):\n",
    "        \n",
    "        SeriesNum = idx+1\n",
    "        \n",
    "        ij.IJ.run(\"Bio-Formats Importer\", f\"open='{lif_path}' color_mode=Default rois_import=[ROI manager] view=Hyperstack stack_order=XYCZT series_{SeriesNum}\")\n",
    "        img = ij.WindowManager.getCurrentImage() # get image, <java class 'ij.ImagePlus'>\n",
    "        # dump_info(img)\n",
    "        # img.show()\n",
    "        img.hide()\n",
    "        \n",
    "        \n",
    "        # Get names and image dimensions\n",
    "        \n",
    "        # Consociate \"palmskin_RGB_RAW\" file_name\n",
    "        file_name = lif_path.split(os.sep)[-1].split(\".\")[0]\n",
    "        file_name_list = re.split(\" |_|-\", file_name)\n",
    "        assert len(file_name_list) == 4, f\"file_name format error, current : '{file_name}', expect like : '20221125_AI005_palmskin_10dpf.lif'\"\n",
    "        file_name = \"_\".join(file_name_list)\n",
    "        \n",
    "        # Get Prop(\"Image name\")\n",
    "        image_name = img.getProp(\"Image name\")\n",
    "        image_name = str(image_name)\n",
    "        \n",
    "        # Check format of 'image_name'\n",
    "        detect_old_new_list = re.findall(\"[RGB]\", image_name)\n",
    "        # print(detect_old_new_list)\n",
    "        image_name_list = re.split(\" |_|-\", image_name)\n",
    "        if len(detect_old_new_list) > 0: failed_cnt, check_dict = check_image_name(image_name_list, \"new_rgb\")\n",
    "        else: failed_cnt, check_dict = check_image_name(image_name_list, \"old_rgb\")\n",
    "        \n",
    "        # Consociate image_name\n",
    "        if (check_dict[\"    format_and_type     \"] == \"old_rgb\") and (failed_cnt == 0): # name check passed, generate new name\n",
    "            image_name_list.pop(3) # palmskin (old name only)\n",
    "            image_name_list.pop(3) # [num]dpf (old name only)\n",
    "            image_name_list.append(\"RGB\")\n",
    "        image_name = \"_\".join(image_name_list)\n",
    "        \n",
    "        # Combine 2 names above\n",
    "        seN = f\"{file_name} - {image_name}\"\n",
    "        \n",
    "        # Get dimension info\n",
    "        img_dimensions = img.getDimensions()\n",
    "        z_length = img.getNumericProperty(\"Image #0|DimensionDescription #6|Length\")\n",
    "        z_slice = img.getNumericProperty(\"Image #0|DimensionDescription #6|NumberOfElements\")\n",
    "        voxel_z = z_length/(z_slice-1)*(10**6)\n",
    "        logger.info(f\"series {SeriesNum:{len(str(seriesCount))}}/{seriesCount} : '{seN}' , Dimensions : {img_dimensions} ( width, height, channels, slices, frames ), Voxel_Z : {voxel_z:.4f} micron\")\n",
    "        \n",
    "        # Print ERRORs when checking 'image_name'\n",
    "        if failed_cnt == -1 : logger.info(check_dict[\"  len(image_name_list)  \"])\n",
    "        if failed_cnt > 0 : logger.info(check_dict[\"     failed warning     \"])\n",
    "        \n",
    "        # Write Log\n",
    "        log_writer.write(f\"|-- processing ...  series {SeriesNum:{len(str(seriesCount))}}/{seriesCount} in {SeriesNum}/{total_lif_file} \\n\")\n",
    "        log_writer.write(f\"|         {seN} \\n\")\n",
    "        log_writer.write(f\"|         Dimensions : {img_dimensions} ( width, height, channels, slices, frames ), Voxel_Z : {voxel_z:.4f} micron \\n\")\n",
    "        if failed_cnt == -1 : log_writer.write(\"| {} \\n\".format(check_dict[\"  len(image_name_list)  \"].strip()))\n",
    "        if failed_cnt > 0: log_writer.write(\"| {} \\n\".format(check_dict[\"     failed warning     \"].strip()))\n",
    "        \n",
    "        \n",
    "        # Start image preprocessing\n",
    "        \n",
    "        \n",
    "        # preprocessing var\n",
    "        # Kuwahara_sampleing = 15\n",
    "        # bf_zproj_type = \"median\" # 'method' is \"avg\", \"min\", \"max\", \"sum\", \"sd\" or \"median\".\n",
    "        # bf_treshold_value = 10\n",
    "        # relative_mask = \"outer\" # \"inner\" or \"outer\"\n",
    "        tif_save_cnt = 0\n",
    "        tif_save_SNdigits = \"02\"\n",
    "        \n",
    "        \n",
    "        # Create sub folder, MetaImage folder\n",
    "        if \"delete\" in seN: subfolder = os.path.join(out_dir_root, \"!~delete\", seN)\n",
    "        else: subfolder = os.path.join(out_dir_root, seN)\n",
    "        assert not Path(subfolder).exists(), f\"target directory exists: '{subfolder}'\"\n",
    "        dir_metaimg = os.path.join(subfolder, \"MetaImage\")\n",
    "        create_new_dir(subfolder, display_in_CLI=False)\n",
    "        create_new_dir(dir_metaimg, display_in_CLI=False)\n",
    "        \n",
    "        \n",
    "        ij.IJ.run(img, \"Set Scale...\", \"distance=2.2 known=1 unit=micron\")\n",
    "        # img.show()\n",
    "        ch_list = channelSplitter.split(img)\n",
    "        # -----------------------------------------------------------------------------------\n",
    "        RGB_direct_max_zproj = direct_max_zproj(ch_list, zProjector, rgbStackMerge, rgbStackConverter)\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_direct_max_zproj, \"RGB_direct_max_zproj\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        ch_B = ch_list[0]\n",
    "        # processed\n",
    "        B_processed = median_R1_and_mean3D_R2(ch_B, zProjector, ij)\n",
    "        tif_save_cnt = save_tif_with_SN(B_processed, \"B_processed\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + Kuwahara Filter\n",
    "        B_processed_Kuwahara = B_processed.duplicate()\n",
    "        ij.IJ.run(B_processed_Kuwahara, \"Kuwahara Filter\", f\"sampling={Kuwahara_sampleing}\")\n",
    "        tif_save_cnt = save_tif_with_SN(B_processed_Kuwahara, f\"B_processed_Kuwahara{Kuwahara_sampleing}\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + HE\n",
    "        B_processed_HE = B_processed.duplicate()\n",
    "        ij.IJ.run(B_processed_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(B_processed_HE, \"B_processed_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + Kuwahara Filter + HE\n",
    "        B_processed_Kuwahara_HE = B_processed_Kuwahara.duplicate()\n",
    "        ij.IJ.run(B_processed_Kuwahara_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(B_processed_Kuwahara_HE, f\"B_processed_Kuwahara{Kuwahara_sampleing}_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # Average 2 Non-HE images\n",
    "        B_processed_fusion = imageCalculator.run(B_processed, B_processed_Kuwahara, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(B_processed_fusion, \"B_processed_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # Average 2 HE images\n",
    "        B_processed_HE_fusion = imageCalculator.run(B_processed_HE, B_processed_Kuwahara_HE, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(B_processed_HE_fusion, \"B_processed_HE_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        ch_G = ch_list[1]\n",
    "        # processed\n",
    "        G_processed = median_R1_and_mean3D_R2(ch_G, zProjector, ij)\n",
    "        tif_save_cnt = save_tif_with_SN(G_processed, \"G_processed\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + Kuwahara Filter\n",
    "        G_processed_Kuwahara = G_processed.duplicate()\n",
    "        ij.IJ.run(G_processed_Kuwahara, \"Kuwahara Filter\", f\"sampling={Kuwahara_sampleing}\")\n",
    "        tif_save_cnt = save_tif_with_SN(G_processed_Kuwahara, f\"G_processed_Kuwahara{Kuwahara_sampleing}\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + HE\n",
    "        G_processed_HE = G_processed.duplicate()\n",
    "        ij.IJ.run(G_processed_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(G_processed_HE, \"G_processed_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + Kuwahara Filter + HE\n",
    "        G_processed_Kuwahara_HE = G_processed_Kuwahara.duplicate()\n",
    "        ij.IJ.run(G_processed_Kuwahara_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(G_processed_Kuwahara_HE, f\"G_processed_Kuwahara{Kuwahara_sampleing}_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # Average 2 Non-HE images\n",
    "        G_processed_fusion = imageCalculator.run(G_processed, G_processed_Kuwahara, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(G_processed_fusion, \"G_processed_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # Average 2 HE images\n",
    "        G_processed_HE_fusion = imageCalculator.run(G_processed_HE, G_processed_Kuwahara_HE, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(G_processed_HE_fusion, \"G_processed_HE_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        ch_R = ch_list[2]\n",
    "        # processed\n",
    "        R_processed = median_R1_and_mean3D_R2(ch_R, zProjector, ij)\n",
    "        tif_save_cnt = save_tif_with_SN(R_processed, \"R_processed\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + Kuwahara Filter\n",
    "        R_processed_Kuwahara = R_processed.duplicate()\n",
    "        ij.IJ.run(R_processed_Kuwahara, \"Kuwahara Filter\", f\"sampling={Kuwahara_sampleing}\")\n",
    "        tif_save_cnt = save_tif_with_SN(R_processed_Kuwahara, f\"R_processed_Kuwahara{Kuwahara_sampleing}\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + HE\n",
    "        R_processed_HE = R_processed.duplicate()\n",
    "        ij.IJ.run(R_processed_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(R_processed_HE, \"R_processed_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # processed + Kuwahara Filter + HE\n",
    "        R_processed_Kuwahara_HE = R_processed_Kuwahara.duplicate()\n",
    "        ij.IJ.run(R_processed_Kuwahara_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(R_processed_Kuwahara_HE, f\"R_processed_Kuwahara{Kuwahara_sampleing}_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # Average 2 Non-HE images\n",
    "        R_processed_fusion = imageCalculator.run(R_processed, R_processed_Kuwahara, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(R_processed_fusion, \"R_processed_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # Average 2 HE images\n",
    "        R_processed_HE_fusion = imageCalculator.run(R_processed_HE, R_processed_Kuwahara_HE, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(R_processed_HE_fusion, \"R_processed_HE_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        # Merge, Enhance Contrast, without Kuwahara Filter\n",
    "        # group_show(R_processed, G_processed, B_processed) # needs to show image before merge\n",
    "        # ij.IJ.run(\"Merge Channels...\", \"c1=[05_R_processed.tif] c2=[03_G_processed.tif] c3=[01_B_processed.tif] create keep\")\n",
    "        # RGB_processed = ij.WindowManager.getCurrentImage()\n",
    "        RGB_processed = rgbStackMerge.mergeChannels([R_processed, G_processed, B_processed], True)\n",
    "        # group_hide(R_processed, G_processed, B_processed)\n",
    "        # ij.IJ.run(RGB_processed, \"RGB Color\", \"\") # will create new window\n",
    "        # RGB_processed_HE = ij.WindowManager.getCurrentImage()\n",
    "        rgbStackConverter.convertToRGB(RGB_processed)\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed, \"RGB_processed\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        RGB_processed_HE = RGB_processed.duplicate()\n",
    "        ij.IJ.run(RGB_processed_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_HE, \"RGB_processed_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # group_hide(RGB_processed, RGB_processed_HE)\n",
    "        \n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        # Merge, Enhance Contrast, with Kuwahara Filter\n",
    "        # group_show(R_processed_Kuwahara, G_processed_Kuwahara, B_processed_Kuwahara) # needs to show image before merge\n",
    "        # ij.IJ.run(\"Merge Channels...\", f\"c1=[06_R_processed_Kuwahara{Kuwahara_sampleing}.tif] c2=[04_G_processed_Kuwahara{Kuwahara_sampleing}.tif] c3=[02_B_processed_Kuwahara{Kuwahara_sampleing}.tif] create keep\")\n",
    "        # RGB_processed_Kuwahara = ij.WindowManager.getCurrentImage()\n",
    "        RGB_processed_Kuwahara = rgbStackMerge.mergeChannels([R_processed_Kuwahara, G_processed_Kuwahara, B_processed_Kuwahara], True)\n",
    "        # group_hide(R_processed_Kuwahara, G_processed_Kuwahara, B_processed_Kuwahara)\n",
    "        # ij.IJ.run(RGB_processed_Kuwahara, \"RGB Color\", \"\") # will create new window\n",
    "        # RGB_processed_Kuwahara_HE = ij.WindowManager.getCurrentImage()\n",
    "        rgbStackConverter.convertToRGB(RGB_processed_Kuwahara)\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_Kuwahara, f\"RGB_processed_Kuwahara{Kuwahara_sampleing}\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        RGB_processed_Kuwahara_HE = RGB_processed_Kuwahara.duplicate()\n",
    "        ij.IJ.run(RGB_processed_Kuwahara_HE, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_Kuwahara_HE, f\"RGB_processed_Kuwahara{Kuwahara_sampleing}_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        # group_hide(RGB_processed_Kuwahara, RGB_processed_Kuwahara_HE)\n",
    "        \n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        # Average 2 Non-HE images and save in RGB, weighted-grayscale\n",
    "        RGB_processed_fusion = imageCalculator.run(RGB_processed, RGB_processed_Kuwahara, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_fusion, \"RGB_processed_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        RGB_processed_fusion2Gray = RGB_processed_fusion.duplicate()\n",
    "        ij.IJ.run(\"Conversions...\", \"scale weighted\")\n",
    "        ij.IJ.run(RGB_processed_fusion2Gray, \"8-bit\", \"\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_fusion2Gray, \"RGB_processed_fusion2Gray\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        # Average 2 HE images and save in RGB, weighted-grayscale\n",
    "        RGB_processed_HE_fusion = imageCalculator.run(RGB_processed_HE, RGB_processed_Kuwahara_HE, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_HE_fusion, \"RGB_processed_HE_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        RGB_processed_HE_fusion2Gray = RGB_processed_HE_fusion.duplicate()\n",
    "        ij.IJ.run(\"Conversions...\", \"scale weighted\")\n",
    "        ij.IJ.run(RGB_processed_HE_fusion2Gray, \"8-bit\", \"\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_HE_fusion2Gray, \"RGB_processed_HE_fusion2Gray\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        # Generate Mask using Bright Field\n",
    "        ch_BF = ch_list[3]\n",
    "        BF_Zproj = zProjector.run(ch_BF, bf_zproj_type) # 'method' is \"avg\", \"min\", \"max\", \"sum\", \"sd\" or \"median\".\n",
    "        tif_save_cnt = save_tif_with_SN(BF_Zproj, f\"BF_Zproj_{bf_zproj_type}\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        ij.IJ.run(BF_Zproj, \"Enhance Contrast...\", \"saturated=0.35 equalize\")\n",
    "        tif_save_cnt = save_tif_with_SN(BF_Zproj, f\"BF_Zproj_{bf_zproj_type}_HE\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        ij.IJ.setRawThreshold(BF_Zproj, 0, bf_treshold_value)\n",
    "        ij.IJ.run(BF_Zproj, \"Convert to Mask\", \"\")\n",
    "        tif_save_cnt = save_tif_with_SN(BF_Zproj, f\"Threshold_0_{bf_treshold_value}\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        threshold_img = imread(f\"{dir_metaimg}/{tif_save_cnt-1:{tif_save_SNdigits}}_Threshold_0_{bf_treshold_value}.tif\") # use scikit-image\n",
    "        outer_rect = create_rect(threshold_img, \"outer\") # use scikit-image\n",
    "        inner_rect = create_rect(threshold_img, \"inner\") # use scikit-image\n",
    "        outer_rect = ij.py.to_imageplus(outer_rect)\n",
    "        inner_rect = ij.py.to_imageplus(inner_rect)\n",
    "        tif_save_cnt = save_tif_with_SN(outer_rect, f\"outer_rect\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        tif_save_cnt = save_tif_with_SN(inner_rect, f\"inner_rect\", dir_metaimg, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        if relative_mask == \"outer\": auto_rect = outer_rect\n",
    "        else: auto_rect = inner_rect\n",
    "        auto_rect = ij.py.to_imageplus(auto_rect)\n",
    "        ij.IJ.run(\"Set Measurements...\", \"area mean min feret's display redirect=None decimal=2\")\n",
    "        ij.IJ.run(auto_rect, \"Analyze Particles...\", \"size=0-Infinity show=Nothing display include add\")\n",
    "        \n",
    "        \n",
    "        # Check ROI\n",
    "        rm.runCommand(\"Show All with labels\")\n",
    "        rm_size = int(rm.getCount())\n",
    "        if rm_size == 1:\n",
    "            rm.save(os.path.normpath(f\"{dir_metaimg}/RoiSet_AutoRect.roi\"))\n",
    "        else:\n",
    "            logger.info(f'      ROI in RoiManager: {rm_size}')\n",
    "            logger.info(f'      #### ERROR : Number of ROI not = 1')\n",
    "            # Write Log\n",
    "            log_writer.write(f\"|         number of ROI = {rm_size} \\n\")\n",
    "            log_writer.write(\"| #### ERROR : Number of ROI not = 1 \\n\") # ERROR:\n",
    "        \n",
    "        \n",
    "        # # Fit ROI with Rect \n",
    "        # auto_rect = mask_img.duplicate()\n",
    "        # ij.IJ.setForegroundColor(255, 255, 255)\n",
    "        # ij.IJ.setBackgroundColor(0, 0, 0)\n",
    "        # auto_rect.show()\n",
    "        # auto_rect.setRoi(rm.getRoi(0))\n",
    "        # ij.IJ.run(auto_rect, \"Fit Rectangle\", \"\")\n",
    "        # ij.IJ.run(auto_rect, \"Fill\", \"slice\")\n",
    "        # auto_rect.hide()\n",
    "        \n",
    "        \n",
    "        # Average with `auto_rect`\n",
    "        RGB_processed_fusion_AvgAutoRect = imageCalculator.run(RGB_processed_fusion, auto_rect, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_fusion_AvgAutoRect, f\"RGB_processed_fusion--AutoRect\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        RGB_processed_HE_fusion_AvgAutoRect = imageCalculator.run(RGB_processed_HE_fusion, auto_rect, \"Average create\")\n",
    "        tif_save_cnt = save_tif_with_SN(RGB_processed_HE_fusion_AvgAutoRect, f\"RGB_processed_HE_fusion--AutoRect\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        \n",
    "        # crop_threshold_roi, save_as_tiff\n",
    "        autocropped_RGB_processed_fusion = crop_threshold_rect(RGB_processed_fusion, rm.getRoi(0), ij)\n",
    "        tif_save_cnt = save_tif_with_SN(autocropped_RGB_processed_fusion, f\"autocropped_RGB_processed_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        autocropped_RGB_processed_HE_fusion = crop_threshold_rect(RGB_processed_HE_fusion, rm.getRoi(0), ij)\n",
    "        tif_save_cnt = save_tif_with_SN(autocropped_RGB_processed_HE_fusion, f\"autocropped_RGB_processed_HE_fusion\", subfolder, tif_save_cnt, tif_save_SNdigits, ij)\n",
    "        \n",
    "        \n",
    "        # Show image\n",
    "        # composite_HE_mix_AvgMaskRect.show()\n",
    "        # composite_HE_mix_AvgMaskRect.hide()\n",
    "        \n",
    "        rm.runCommand(\"Deselect\")\n",
    "        rm.runCommand(\"Delete\")\n",
    "        ij.IJ.run(\"Clear Results\", \"\")\n",
    "        ij.IJ.run(\"Close All\", \"\")\n",
    "        log_writer.write(f\"| \\n\") # make Log file looks better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(rm.getCount()) > 0:\n",
    "    rm.runCommand(\"Deselect\")\n",
    "    rm.runCommand(\"Delete\")\n",
    "    ij.IJ.run(\"Clear Results\", \"\")\n",
    "ij.IJ.run(\"Close All\", \"\")\n",
    "\n",
    "\n",
    "logger.info(\"MODE: UPDATE\") if UPDATE_MODE else logger.info(\"MODE: CREATE\")\n",
    "\n",
    "# Scan Leica LIF file\n",
    "lif_path_list = []\n",
    "if nas_dl_source_dirs:\n",
    "    for source_dir in nas_dl_source_dirs:\n",
    "        temp_list = list(raw_lif_dir.joinpath(source_dir).glob(\"**/*.lif\"))\n",
    "        lif_path_list.extend(temp_list)\n",
    "else:\n",
    "    lif_path_list = list(raw_lif_dir.glob(\"**/*.lif\"))\n",
    "lif_path_list.sort(key=lambda x: str(x).split(os.sep)[-1])\n",
    "# lif_path_list = lif_path_list[:1]\n",
    "for lif_path in lif_path_list: \n",
    "    logger.info(f'lif_path_list {type(lif_path)}: {lif_path}')\n",
    "logger.info(f\"[ found {len(lif_path_list)} lif files ]\")\n",
    "\n",
    "\n",
    "# Create Log writer\n",
    "time_stamp = datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "log_path = os.path.join(palmskin_preprocess_dir, f\"{{Logs}}_{{ij_palmskin_preprocess}}_{time_stamp}.log\")\n",
    "log_writer = open(log_path, mode=\"w\")\n",
    "logger.info(f'log_writer {type(log_writer)}: {log_writer} \\n')\n",
    "\n",
    "\n",
    "config_save_path = palmskin_preprocess_dir.joinpath(\"palmskin_preprocess_config.toml\")\n",
    "if UPDATE_MODE:\n",
    "    assert config_save_path.exists(), f\"UpdateError, Can't find existing config: '{config_save_path}'\" # find existing config\n",
    "    with open(config_save_path, mode=\"r\") as f_reader:\n",
    "        preprocess_kwargs = toml.load(f_reader)[\"param\"]\n",
    "else:\n",
    "    preprocess_kwargs = config[\"param\"]\n",
    "    with open(config_save_path, mode=\"w\") as f_writer:\n",
    "        tomlkit.dump(config, f_writer)\n",
    "\n",
    "\n",
    "for i, lif_path in enumerate(lif_path_list):\n",
    "    \n",
    "    lif_path = str(lif_path)\n",
    "    logger.info(f\"Processing ... {i+1}/{len(lif_path_list)}\")\n",
    "    \n",
    "    # Write Log\n",
    "    log_writer.write(\"\\n\\n\\n\")\n",
    "    log_writer.write(f\"|-----------------------------------------  Processing ... {i+1}/{len(lif_path_list)}  ----------------------------------------- \\n\")\n",
    "    log_writer.write(f\"| \\n\")\n",
    "    log_writer.write(f\"|         LIF_FILE : {lif_path.split(os.sep)[-1]} \\n\")\n",
    "    log_writer.write(f\"| \\n\")\n",
    "    \n",
    "    # process current LIF_FILE\n",
    "    single_palmskin_preprocess(lif_path, len(lif_path_list), palmskin_preprocess_dir, logger, log_writer, **preprocess_kwargs)\n",
    "    logger.info(\"\\n\") # make CLI output looks better.\n",
    "\n",
    "\n",
    "logger.info(\" -- finished --\")\n",
    "log_writer.write(\"\\n\\n\\n-----------------------------------------  finished  ----------------------------------------- \\n\")\n",
    "log_writer.close()\n",
    "# rm.close()\n",
    "# ij.WindowManager.closeAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae46fe3be2f97d3a16702042bc6c7abd422dd0bfb5ce5527ad30c3a287e1c756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
